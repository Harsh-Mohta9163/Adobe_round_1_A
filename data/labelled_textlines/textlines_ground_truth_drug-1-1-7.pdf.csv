text_a,span_text_a,text_b,span_text_b,normalized_vertical_gap,indentation_change,same_alignment,is_centered_A,is_centered_B,font_size_a,font_size_b,font_size_diff,same_font,is_bold_A,is_bold_B,is_italic_A,is_italic_B,is_monospace_A,is_monospace_B,same_bold,same_italic,same_monospace,line_a_ends_punctuation,line_b_starts_lowercase,is_linea_in_rectangle,is_lineb_in_rectangle,both_in_table,neither_in_table,is_linea_hashed,is_lineb_hashed,both_hashed,neither_hashed,page_number_a,page_number_b,label
OPEN,OPEN,www.nature.com/scientificreportshttp://www.nature.com/scientificreports,www.nature.com/scientificreports,-513.27,297,0,0,0,18,10,-8,0,1,0,0,0,0,0,0,1,1,0,1,0,1,0,0,1,0,0,0,1,1,1
www.nature.com/scientificreportshttp://www.nature.com/scientificreports,www.nature.com/scientificreports,Drug discovery and mechanism prediction with explainable graph neural networks,prediction with explainable graph,492.76,-234.66,0,0,1,10,26,16,0,0,1,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,0,1,1,0
Drug discovery and mechanism prediction with explainable graph neural networks,prediction with explainable graph,"Conghao Wang, Gaurav Asok Kumar & Jagath C. Rajapakse ?","Conghao Wang, Gaurav Asok Kumar & Jagath C. Rajapakse?",133.15,0,1,1,1,26,10,-16,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,1,1,0,0,0,1,1,0
"Conghao Wang, Gaurav Asok Kumar & Jagath C. Rajapakse ?","Conghao Wang, Gaurav Asok Kumar & Jagath C. Rajapakse?",Apprehension of drug action mechanism is paramount for drug response prediction and precision,Apprehension of drug action mechanism is paramount for drug response prediction and precision,32.95,0,1,1,1,10,9,-1,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,0
Apprehension of drug action mechanism is paramount for drug response prediction and precision,Apprehension of drug action mechanism is paramount for drug response prediction and precision,medicine. The unprecedented development of machine learning and deep learning algorithms has,medicine. The unprecedented development of machine learning and deep learning algorithms has,1,0,1,1,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
medicine. The unprecedented development of machine learning and deep learning algorithms has,medicine. The unprecedented development of machine learning and deep learning algorithms has,"expedited the drug response prediction research. However, existing methods mainly focus on forward","expedited the drug response prediction research. However, existing methods mainly focus on forward",1,0,1,1,0,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"expedited the drug response prediction research. However, existing methods mainly focus on forward","expedited the drug response prediction research. However, existing methods mainly focus on forward","encoding of drugs, which is to obtain an accurate prediction of the response levels, but omitted to","encoding of drugs, which is to obtain an accurate prediction of the response levels, but omitted to",1,0,1,0,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"encoding of drugs, which is to obtain an accurate prediction of the response levels, but omitted to","encoding of drugs, which is to obtain an accurate prediction of the response levels, but omitted to",decipher the reaction mechanism between drug molecules and genes. We propose the eXplainable,decipher the reaction mechanism between drug molecules and genes. We propose the eXplainable,1,0,1,1,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
decipher the reaction mechanism between drug molecules and genes. We propose the eXplainable,decipher the reaction mechanism between drug molecules and genes. We propose the eXplainable,Graph-based Drug response Prediction XGDP approach that achieves a precise drug response,Graph-based Drug response Prediction (XGDP) approach that achieves a precise drug response,1,0,1,1,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,1
Graph-based Drug response Prediction XGDP approach that achieves a precise drug response,Graph-based Drug response Prediction (XGDP) approach that achieves a precise drug response,prediction and reveals the comprehensive mechanism of action between drugs and their targets.,prediction and reveals the comprehensive mechanism of action between drugs and their targets.,1,0,1,1,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
prediction and reveals the comprehensive mechanism of action between drugs and their targets.,prediction and reveals the comprehensive mechanism of action between drugs and their targets.,"XGDP represents drugs with molecular graphs, which naturally preserve the structural information of","XGDP represents drugs with molecular graphs, which naturally preserve the structural information of",1,0,1,1,0,9,9,0,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,1,1,1
"XGDP represents drugs with molecular graphs, which naturally preserve the structural information of","XGDP represents drugs with molecular graphs, which naturally preserve the structural information of",molecules and a Graph Neural Network module is applied to learn the latent features of molecules.,molecules and a Graph Neural Network module is applied to learn the latent features of molecules.,1,0,1,0,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
molecules and a Graph Neural Network module is applied to learn the latent features of molecules.,molecules and a Graph Neural Network module is applied to learn the latent features of molecules.,Gene expression data from cancer cell lines are incorporated and processed by a Convolutional,Gene expression data from cancer cell lines are incorporated and processed by a Convolutional,1,0,1,1,1,9,9,0,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,1,1,1
Gene expression data from cancer cell lines are incorporated and processed by a Convolutional,Gene expression data from cancer cell lines are incorporated and processed by a Convolutional,Neural Network module. A couple of deep learning attribution algorithms are leveraged to interpret,Neural Network module. A couple of deep learning attribution algorithms are leveraged to interpret,1,0,1,1,0,9,9,0,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,1
Neural Network module. A couple of deep learning attribution algorithms are leveraged to interpret,Neural Network module. A couple of deep learning attribution algorithms are leveraged to interpret,interactions between drug molecular features and genes. We demonstrate that XGDP not only,interactions between drug molecular features and genes. We demonstrate that XGDP not only,1,0,1,0,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
interactions between drug molecular features and genes. We demonstrate that XGDP not only,interactions between drug molecular features and genes. We demonstrate that XGDP not only,enhances the prediction accuracy compared to pioneering works but is also capable of capturing the,enhances the prediction accuracy compared to pioneering works but is also capable of capturing the,1,0,1,1,0,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
enhances the prediction accuracy compared to pioneering works but is also capable of capturing the,enhances the prediction accuracy compared to pioneering works but is also capable of capturing the,salient functional groups of drugs and interactions with significant genes of cancer cells.,salient functional groups of drugs and interactions with significant genes of cancer cells.,1,0,1,0,1,9,9,0,1,1,1,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
salient functional groups of drugs and interactions with significant genes of cancer cells.,salient functional groups of drugs and interactions with significant genes of cancer cells.,"Aiming at facilitating precision medicine in complex disease such as cancer, computational approaches have","Aiming at facilitating precision medicine in complex disease such as cancer, computational approaches have",32.86,0,1,1,0,9,9,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,1,1,0
"Aiming at facilitating precision medicine in complex disease such as cancer, computational approaches have","Aiming at facilitating precision medicine in complex disease such as cancer, computational approaches have","been increasingly proposed to delve into the reactions between drugs and cancer cells 1 . Recently, numerous","been increasingly proposed to delve into the reactions between drugs and cancer cells1. Recently, numerous",-7.87,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"been increasingly proposed to delve into the reactions between drugs and cancer cells 1 . Recently, numerous","been increasingly proposed to delve into the reactions between drugs and cancer cells1. Recently, numerous","machine learning 2,3 and deep learning 4,5 methods have been successfully applied to predict drug response levels","machine learning2,3 and deep learning4,5 methods have been successfully applied to predict drug response levels",-7.87,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"machine learning 2,3 and deep learning 4,5 methods have been successfully applied to predict drug response levels","machine learning2,3 and deep learning4,5 methods have been successfully applied to predict drug response levels","precisely. However, most of them target at phenotypic screening 6 and do not come along with a reasonable","precisely. However, most of them target at phenotypic screening6 and do not come along with a reasonable",-7.87,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"precisely. However, most of them target at phenotypic screening 6 and do not come along with a reasonable","precisely. However, most of them target at phenotypic screening6 and do not come along with a reasonable","interpretability, rendering drug reaction mechanism obscure. To expedite precision medicine, it is crucial to","interpretability, rendering drug reaction mechanism obscure. To expedite precision medicine, it is crucial to",-7.87,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"interpretability, rendering drug reaction mechanism obscure. To expedite precision medicine, it is crucial to","interpretability, rendering drug reaction mechanism obscure. To expedite precision medicine, it is crucial to",elucidate the mechanism of action of drugs and thereby promote novel drug discovery.,elucidate the mechanism of action of drugs and thereby promote novel drug discovery.,-7.87,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
elucidate the mechanism of action of drugs and thereby promote novel drug discovery.,elucidate the mechanism of action of drugs and thereby promote novel drug discovery.,A proper representation of a drug molecule is pivotal to any drug response prediction methods. According,A proper representation of a drug molecule is pivotal to any drug response prediction methods. According,-7.87,12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,1,1,0
A proper representation of a drug molecule is pivotal to any drug response prediction methods. According,A proper representation of a drug molecule is pivotal to any drug response prediction methods. According,"to recent reviews of molecular representations of drugs 7, there are mainly three categories of representation:","to recent reviews of molecular representations of drugs7, there are mainly three categories of representation:",-7.87,-12,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"to recent reviews of molecular representations of drugs 7, there are mainly three categories of representation:","to recent reviews of molecular representations of drugs7, there are mainly three categories of representation:","linear notations, molecular fingerprints FPs, and graph notations. Linear notations encode the molecule with","linear notations, molecular fingerprints (FPs), and graph notations. Linear notations encode the molecule with",-7.87,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,1,1,1
"linear notations, molecular fingerprints FPs, and graph notations. Linear notations encode the molecule with","linear notations, molecular fingerprints (FPs), and graph notations. Linear notations encode the molecule with",a vector of string. Two frequently used instances of linear notations are the IUPAC International Chemical,a vector of string. Two frequently used instances of linear notations are the IUPAC International Chemical,-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
a vector of string. Two frequently used instances of linear notations are the IUPAC International Chemical,a vector of string. Two frequently used instances of linear notations are the IUPAC International Chemical,"Identifier InChI 8, and the Simplified Molecular-Input Line-Entry System SMILES 9 . SMILES strings are more","Identifier (InChI)8, and the Simplified Molecular-Input Line-Entry System (SMILES)9. SMILES strings are more",-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,1
"Identifier InChI 8, and the Simplified Molecular-Input Line-Entry System SMILES 9 . SMILES strings are more","Identifier (InChI)8, and the Simplified Molecular-Input Line-Entry System (SMILES)9. SMILES strings are more",widely used since it encodes the chemical structure into a string of ASCII characters. CaDRReS 10 applied Matrix,widely used since it encodes the chemical structure into a string of ASCII characters. CaDRReS10 applied Matrix,-7.87,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
widely used since it encodes the chemical structure into a string of ASCII characters. CaDRReS 10 applied Matrix,widely used since it encodes the chemical structure into a string of ASCII characters. CaDRReS10 applied Matrix,Factorization to learn the latent features of drugs with the cell line gene expression data and drug sensitivity,Factorization to learn the latent features of drugs with the cell line gene expression data and drug sensitivity,-7.87,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,1
Factorization to learn the latent features of drugs with the cell line gene expression data and drug sensitivity,Factorization to learn the latent features of drugs with the cell line gene expression data and drug sensitivity,"matrix, and compared the similarity scores derived from learned features and SMILES notations. tCNNs 11 and","matrix, and compared the similarity scores derived from learned features and SMILES notations. tCNNs11 and",-7.87,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"matrix, and compared the similarity scores derived from learned features and SMILES notations. tCNNs 11 and","matrix, and compared the similarity scores derived from learned features and SMILES notations. tCNNs11 and",CDRScan 12 adopted Convolutional Neural Networks CNN to learn a latent representation of drugs SMILES,CDRScan12 adopted Convolutional Neural Networks (CNN) to learn a latent representation of drugs SMILES,-7.87,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,1
CDRScan 12 adopted Convolutional Neural Networks CNN to learn a latent representation of drugs SMILES,CDRScan12 adopted Convolutional Neural Networks (CNN) to learn a latent representation of drugs SMILES,"vector. CNN is a powerful deep learning approach to handle grid-like data in the domain of texts and images,","vector. CNN is a powerful deep learning approach to handle grid-like data in the domain of texts and images,",-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"vector. CNN is a powerful deep learning approach to handle grid-like data in the domain of texts and images,","vector. CNN is a powerful deep learning approach to handle grid-like data in the domain of texts and images,","which can be used to encode the linear notations of drugs as well. However, the SMILES notation does not","which can be used to encode the linear notations of drugs as well. However, the SMILES notation does not",-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"which can be used to encode the linear notations of drugs as well. However, the SMILES notation does not","which can be used to encode the linear notations of drugs as well. However, the SMILES notation does not",possess the property of locality like texts and images since the physically adjacent atoms in the sequence of,possess the property of locality like texts and images since the physically adjacent atoms in the sequence of,-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
possess the property of locality like texts and images since the physically adjacent atoms in the sequence of,possess the property of locality like texts and images since the physically adjacent atoms in the sequence of,"SMILES string can be far away from each other in the real molecular environment, and therefore dimisses the","SMILES string can be far away from each other in the real molecular environment, and therefore dimisses the",-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,1
"SMILES string can be far away from each other in the real molecular environment, and therefore dimisses the","SMILES string can be far away from each other in the real molecular environment, and therefore dimisses the",structural information of molecules.,structural information of molecules.,-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
structural information of molecules.,structural information of molecules.,"Molecular fingerprints, such as Molecular Access System MACCS 13 and Chemically Advanced Template","Molecular fingerprints, such as Molecular Access System (MACCS)13 and Chemically Advanced Template",-7.87,12,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,1,1,0
"Molecular fingerprints, such as Molecular Access System MACCS 13 and Chemically Advanced Template","Molecular fingerprints, such as Molecular Access System (MACCS)13 and Chemically Advanced Template","Search 14, identify the key structures of a molecule and represent them with a binary vector where each bit","Search14, identify the key structures of a molecule and represent them with a binary vector where each bit",-7.87,-12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,1
"Search 14, identify the key structures of a molecule and represent them with a binary vector where each bit","Search14, identify the key structures of a molecule and represent them with a binary vector where each bit",denotes the structures existence. A drawback of this kind of representation is that only the pre-defined structure,denotes the structures existence. A drawback of this kind of representation is that only the pre-defined structure,-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
denotes the structures existence. A drawback of this kind of representation is that only the pre-defined structure,denotes the structures existence. A drawback of this kind of representation is that only the pre-defined structure,"can be recognized, which might hamper the discovery of novel structures. To circumvent this problem, circular","can be recognized, which might hamper the discovery of novel structures. To circumvent this problem, circular",-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"can be recognized, which might hamper the discovery of novel structures. To circumvent this problem, circular","can be recognized, which might hamper the discovery of novel structures. To circumvent this problem, circular",fingerprints such as Extended Connectivity FPs ECFPs based on Morgan algorithm 15 has been proposed to,fingerprints such as Extended Connectivity FPs (ECFPs) based on Morgan algorithm15 has been proposed to,-7.87,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
fingerprints such as Extended Connectivity FPs ECFPs based on Morgan algorithm 15 has been proposed to,fingerprints such as Extended Connectivity FPs (ECFPs) based on Morgan algorithm15 has been proposed to,iteratively search the substructures of molecules rather than pre-define them. The information of these crucial,iteratively search the substructures of molecules rather than pre-define them. The information of these crucial,-7.87,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
iteratively search the substructures of molecules rather than pre-define them. The information of these crucial,iteratively search the substructures of molecules rather than pre-define them. The information of these crucial,"structures is preserved in this kind of representation, whereas the positional information is lost, and we can","structures is preserved in this kind of representation, whereas the positional information is lost, and we can",-7.87,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
"structures is preserved in this kind of representation, whereas the positional information is lost, and we can","structures is preserved in this kind of representation, whereas the positional information is lost, and we can",hardly track where these sub-structures occur in the molecule. DeepDSC 16 combines Morgan fingerprints of,hardly track where these sub-structures occur in the molecule. DeepDSC16 combines Morgan fingerprints of,-7.87,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
hardly track where these sub-structures occur in the molecule. DeepDSC 16 combines Morgan fingerprints of,hardly track where these sub-structures occur in the molecule. DeepDSC16 combines Morgan fingerprints of,drugs into the latent features of cancer cell lines learned by an auto-encoder. S2DV 17 applied word2vec 18 to,drugs into the latent features of cancer cell lines learned by an auto-encoder. S2DV17 applied word2vec18 to,-7.87,0,1,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1
drugs into the latent features of cancer cell lines learned by an auto-encoder. S2DV 17 applied word2vec 18 to,drugs into the latent features of cancer cell lines learned by an auto-encoder. S2DV17 applied word2vec18 to,"College of Computing and Data Science, Nanyang Technological University, Singapore 639798, Singapore. ? email:","College of Computing and Data Science, Nanyang Technological University, Singapore 639798, Singapore. ?email:",65.09,-0.09,1,1,1,9,8.5,-0.5,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,0
"College of Computing and Data Science, Nanyang Technological University, Singapore 639798, Singapore. ? email:","College of Computing and Data Science, Nanyang Technological University, Singapore 639798, Singapore. ?email:",ASJagath@ntu.edu.sg,ASJagath@ntu.edu.sg,-0.45,0,1,1,0,8.5,8.5,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,1,1,1
ASJagath@ntu.edu.sg,ASJagath@ntu.edu.sg,Scientific Reports 2025 15:179 https://doi.org/10.1038/s41598-024-83090-3 1,| https://doi.org/10.1038/s41598-024-83090-3,63.52,70.04,0,0,1,8.5,8,-0.5,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,1,1,0
"tokenize ECFP features or SIMLES as drugs representations. Ma et al. used Atom Pairs AP, MACCS and","tokenize ECFP features or SIMLES as drugs representations. Ma et al. used Atom Pairs (AP), MACCS and","circular fingerprints as the descriptor of drugs, and performed the quantitative structure activity relationship","circular fingerprints as the descriptor of drugs, and performed the quantitative structure activity relationship",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"circular fingerprints as the descriptor of drugs, and performed the quantitative structure activity relationship","circular fingerprints as the descriptor of drugs, and performed the quantitative structure activity relationship",QSAR study with a Deep Neural Network 19 .,(QSAR) study with a Deep Neural Network19.,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,2,2,1
QSAR study with a Deep Neural Network 19 .,(QSAR) study with a Deep Neural Network19.,Graph notations have recently been brought under the spotlight in the domain of drug representation.,Graph notations have recently been brought under the spotlight in the domain of drug representation.,-0.14,12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,2,2,1
Graph notations have recently been brought under the spotlight in the domain of drug representation.,Graph notations have recently been brought under the spotlight in the domain of drug representation.,"Previously, compromising on computational complexity of molecular structures and the confined power of graph","Previously, compromising on computational complexity of molecular structures and the confined power of graph",-0.14,-12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,2,2,1
"Previously, compromising on computational complexity of molecular structures and the confined power of graph","Previously, compromising on computational complexity of molecular structures and the confined power of graph","learning, aforementioned methods are preferred to denote a molecule even at the cost of loss of information.","learning, aforementioned methods are preferred to denote a molecule even at the cost of loss of information.",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"learning, aforementioned methods are preferred to denote a molecule even at the cost of loss of information.","learning, aforementioned methods are preferred to denote a molecule even at the cost of loss of information.","However, with the advent of Graph Neural Networks GNN in the deep learning domain in recent years, it is","However, with the advent of Graph Neural Networks (GNN) in the deep learning domain in recent years, it is",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,2,2,1
"However, with the advent of Graph Neural Networks GNN in the deep learning domain in recent years, it is","However, with the advent of Graph Neural Networks (GNN) in the deep learning domain in recent years, it is",now feasible to store and analyze the information from molecules in graphs 20 .,now feasible to store and analyze the information from molecules in graphs20.,-0.14,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
now feasible to store and analyze the information from molecules in graphs 20 .,now feasible to store and analyze the information from molecules in graphs20.,"Numerous variants of GNN models have been applied in the pharmaceutical domain 21,22 and demonstrated","Numerous variants of GNN models have been applied in the pharmaceutical domain21,22 and demonstrated",-0.14,12,0,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,2,2,0
"Numerous variants of GNN models have been applied in the pharmaceutical domain 21,22 and demonstrated","Numerous variants of GNN models have been applied in the pharmaceutical domain21,22 and demonstrated",to learn the latent representation of the molecular graphs trading off the descriptive power against complexity. A,to learn the latent representation of the molecular graphs trading off the descriptive power against complexity. A,-0.14,-12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
to learn the latent representation of the molecular graphs trading off the descriptive power against complexity. A,to learn the latent representation of the molecular graphs trading off the descriptive power against complexity. A,Graph Convolution Network GCN model 23 was proposed to predict the chemical properties of molecules and,Graph Convolution Network (GCN) model23 was proposed to predict the chemical properties of molecules and,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,2,2,1
Graph Convolution Network GCN model 23 was proposed to predict the chemical properties of molecules and,Graph Convolution Network (GCN) model23 was proposed to predict the chemical properties of molecules and,discover porous materials. The typical message passing pattern of GNN intrinsically weakens the influence of,discover porous materials. The typical message passing pattern of GNN intrinsically weakens the influence of,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
discover porous materials. The typical message passing pattern of GNN intrinsically weakens the influence of,discover porous materials. The typical message passing pattern of GNN intrinsically weakens the influence of,"distal nodes, which might contradict the real case in the molecule, where atoms from a long topological distance","distal nodes, which might contradict the real case in the molecule, where atoms from a long topological distance",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"distal nodes, which might contradict the real case in the molecule, where atoms from a long topological distance","distal nodes, which might contradict the real case in the molecule, where atoms from a long topological distance",can still interact such as intramolecular hydrogen bonds. An Attentive FP model proposed by 24 leveraged the,can still interact such as intramolecular hydrogen bonds. An Attentive FP model proposed by24 leveraged the,-0.14,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
can still interact such as intramolecular hydrogen bonds. An Attentive FP model proposed by 24 leveraged the,can still interact such as intramolecular hydrogen bonds. An Attentive FP model proposed by24 leveraged the,graph attention mechanism to learn the impact of a node to another. This model addressed the above issue by,graph attention mechanism to learn the impact of a node to another. This model addressed the above issue by,-0.14,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
graph attention mechanism to learn the impact of a node to another. This model addressed the above issue by,graph attention mechanism to learn the impact of a node to another. This model addressed the above issue by,updating the nodes with a trade-off between the topological distance and the possibly intangible linkage with,updating the nodes with a trade-off between the topological distance and the possibly intangible linkage with,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
updating the nodes with a trade-off between the topological distance and the possibly intangible linkage with,updating the nodes with a trade-off between the topological distance and the possibly intangible linkage with,"the attention mechanism. GraphDRP 25 enhanced the tCNN 11 prediction precision by substituting the drugCNN module with GNN to better encapsulate the drug features. DeepCDR 26, TGSA 27 and DualGCN 28 further",the attention mechanism. GraphDRP25 enhanced the tCNN11 prediction precision by substituting the drug-,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"the attention mechanism. GraphDRP 25 enhanced the tCNN 11 prediction precision by substituting the drugCNN module with GNN to better encapsulate the drug features. DeepCDR 26, TGSA 27 and DualGCN 28 further",the attention mechanism. GraphDRP25 enhanced the tCNN11 prediction precision by substituting the drug-,explored integrating multi-omics profiles for a better representation of cancer cell lines. Besides modeling drugs,explored integrating multi-omics profiles for a better representation of cancer cell lines. Besides modeling drugs,0.5,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
explored integrating multi-omics profiles for a better representation of cancer cell lines. Besides modeling drugs,explored integrating multi-omics profiles for a better representation of cancer cell lines. Besides modeling drugs,"with GNN, SWNet 29 introduced a self-attention mechanism to bring drug similarity into the consideration when","with GNN, SWNet29 introduced a self-attention mechanism to bring drug similarity into the consideration when",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"with GNN, SWNet 29 introduced a self-attention mechanism to bring drug similarity into the consideration when","with GNN, SWNet29 introduced a self-attention mechanism to bring drug similarity into the consideration when",learning cell features. An algebraic graph-assisted bidirectional transformer AGBT model 30 was developed,learning cell features. An algebraic graph-assisted bidirectional transformer (AGBT) model30 was developed,-0.14,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
learning cell features. An algebraic graph-assisted bidirectional transformer AGBT model 30 was developed,learning cell features. An algebraic graph-assisted bidirectional transformer (AGBT) model30 was developed,to encode the 3D structure of molecules into algebraic graphs. And Molecular Topographic Map MTM was,to encode the 3D structure of molecules into algebraic graphs. And Molecular Topographic Map (MTM) was,-0.14,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
to encode the 3D structure of molecules into algebraic graphs. And Molecular Topographic Map MTM was,to encode the 3D structure of molecules into algebraic graphs. And Molecular Topographic Map (MTM) was,generated from atom features by using Generative Topographic Mapping GTM 31 to represent drugs in graphs 32 .,generated from atom features by using Generative Topographic Mapping (GTM)31 to represent drugs in graphs32.,-0.14,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
generated from atom features by using Generative Topographic Mapping GTM 31 to represent drugs in graphs 32 .,generated from atom features by using Generative Topographic Mapping (GTM)31 to represent drugs in graphs32.,"In this study, we propose a framework named eXplainable Graph-based Drug response Prediction XGDP","In this study, we propose a framework named eXplainable Graph-based Drug response Prediction (XGDP)",-0.14,12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,2,2,1
"In this study, we propose a framework named eXplainable Graph-based Drug response Prediction XGDP","In this study, we propose a framework named eXplainable Graph-based Drug response Prediction (XGDP)","for predicting anti-cancer drug responses and discovering the mechanism of action. The architecture of XGDP,","for predicting anti-cancer drug responses and discovering the mechanism of action. The architecture of XGDP,",-0.14,-12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"for predicting anti-cancer drug responses and discovering the mechanism of action. The architecture of XGDP,","for predicting anti-cancer drug responses and discovering the mechanism of action. The architecture of XGDP,","as shown in Fig. 1, is composed of 3 modules. The GNN module learns the latent features of drugs denoted","as shown in Fig. 1, is composed of 3 modules. The GNN module learns the latent features of drugs denoted",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"as shown in Fig. 1, is composed of 3 modules. The GNN module learns the latent features of drugs denoted","as shown in Fig. 1, is composed of 3 modules. The GNN module learns the latent features of drugs denoted",by molecular graphs. We propose to use a set of novel features adapted from ECFPs as the node features and,by molecular graphs. We propose to use a set of novel features adapted from ECFPs as the node features and,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
by molecular graphs. We propose to use a set of novel features adapted from ECFPs as the node features and,by molecular graphs. We propose to use a set of novel features adapted from ECFPs as the node features and,incorporate chemical bond types as the edge features in our graph convolutional layers. And the CNN module,incorporate chemical bond types as the edge features in our graph convolutional layers. And the CNN module,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
incorporate chemical bond types as the edge features in our graph convolutional layers. And the CNN module,incorporate chemical bond types as the edge features in our graph convolutional layers. And the CNN module,"learns the latent features of cancer cell lines from its gene expression profiles. Then, a cross-attention module","learns the latent features of cancer cell lines from its gene expression profiles. Then, a cross-attention module",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"learns the latent features of cancer cell lines from its gene expression profiles. Then, a cross-attention module","learns the latent features of cancer cell lines from its gene expression profiles. Then, a cross-attention module","is utilized to integrate latend features from drugs and cell lines, and thereafter predict the drug responses. The","is utilized to integrate latend features from drugs and cell lines, and thereafter predict the drug responses. The",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"is utilized to integrate latend features from drugs and cell lines, and thereafter predict the drug responses. The","is utilized to integrate latend features from drugs and cell lines, and thereafter predict the drug responses. The","experimental results indicate that, with novel node and edge features, our model outperformed the previous","experimental results indicate that, with novel node and edge features, our model outperformed the previous",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"experimental results indicate that, with novel node and edge features, our model outperformed the previous","experimental results indicate that, with novel node and edge features, our model outperformed the previous","drug response prediction methods 11,25 . Moreover, we leverage deep learning attribution approaches such as","drug response prediction methods11,25. Moreover, we leverage deep learning attribution approaches such as",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"drug response prediction methods 11,25 . Moreover, we leverage deep learning attribution approaches such as","drug response prediction methods11,25. Moreover, we leverage deep learning attribution approaches such as",GNNExplainer 33 and Integrated Gradients 34 to interpret our model. It is demonstrated that our developed,GNNExplainer33 and Integrated Gradients34 to interpret our model. It is demonstrated that our developed,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,2,2,1
GNNExplainer 33 and Integrated Gradients 34 to interpret our model. It is demonstrated that our developed,GNNExplainer33 and Integrated Gradients34 to interpret our model. It is demonstrated that our developed,"model is capable of identifying the active substructures of drugs and the significant genes in cancer cells, and","model is capable of identifying the active substructures of drugs and the significant genes in cancer cells, and",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"model is capable of identifying the active substructures of drugs and the significant genes in cancer cells, and","model is capable of identifying the active substructures of drugs and the significant genes in cancer cells, and",thus revealing the mechanism of action of drugs.,thus revealing the mechanism of action of drugs.,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
thus revealing the mechanism of action of drugs.,thus revealing the mechanism of action of drugs.,Methods,Methods,0.53,0,1,0,0,9,11,2,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,2,2,0
Methods,Methods,Datasets,Datasets,-0.14,0,1,0,0,11,10,-1,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,2,2,0
Datasets,Datasets,We propose a deep learning-based approach to predict the drug responses of cancer with molecular graphs,We propose a deep learning-based approach to predict the drug responses of cancer with molecular graphs,-0.08,0,1,0,0,10,9,-1,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,2,2,0
We propose a deep learning-based approach to predict the drug responses of cancer with molecular graphs,We propose a deep learning-based approach to predict the drug responses of cancer with molecular graphs,of drugs and gene expression data from cancer cell lines. The dataset was acquired from Genomics of Drug,of drugs and gene expression data from cancer cell lines. The dataset was acquired from Genomics of Drug,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
of drugs and gene expression data from cancer cell lines. The dataset was acquired from Genomics of Drug,of drugs and gene expression data from cancer cell lines. The dataset was acquired from Genomics of Drug,Fig. 1 . The architecture of the proposed model XGDP for drug response and mechanism prediction.,Fig. 1.  The architecture of the proposed model XGDP for drug response and mechanism prediction.,14.58,0,1,0,0,9,9,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,2,2,0
Fig. 1 . The architecture of the proposed model XGDP for drug response and mechanism prediction.,Fig. 1.  The architecture of the proposed model XGDP for drug response and mechanism prediction.,"Molecular graph, node features and edge features are extracted from the drug molecule, and GNN is used for","Molecular graph, node features and edge features are extracted from the drug molecule, and GNN is used for",-0.14,0,1,0,0,9,9,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,2,2,1
"Molecular graph, node features and edge features are extracted from the drug molecule, and GNN is used for","Molecular graph, node features and edge features are extracted from the drug molecule, and GNN is used for",learning the latent features of drugs. CNN is applied to compress the gene expression features from cancer cell,learning the latent features of drugs. CNN is applied to compress the gene expression features from cancer cell,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
learning the latent features of drugs. CNN is applied to compress the gene expression features from cancer cell,learning the latent features of drugs. CNN is applied to compress the gene expression features from cancer cell,"lines. Then two multi-head cross-attention layers are leveraged to combine drug and cell features, and the drug","lines. Then two multi-head cross-attention layers are leveraged to combine drug and cell features, and the drug",-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
"lines. Then two multi-head cross-attention layers are leveraged to combine drug and cell features, and the drug","lines. Then two multi-head cross-attention layers are leveraged to combine drug and cell features, and the drug",response is predicted with the integrated features.,response is predicted with the integrated features.,-0.14,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,2,2,1
response is predicted with the integrated features.,response is predicted with the integrated features.,Scientific Reports 2025 15:179 https://doi.org/10.1038/s41598-024-83090-3 2,| https://doi.org/10.1038/s41598-024-83090-3,1.47,69.94,0,0,1,9,8,-1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,2,2,1
"Sensitivity in Cancer GDSC database 35, including response levels in IC50 formats, drug names, and cell line","Sensitivity in Cancer (GDSC) database35, including response levels in IC50 formats, drug names, and cell line",names. Gene expression data of cell lines are obtained from Cancer Cell Line Encyclopedia CCLE 36 . Drugs,names. Gene expression data of cell lines are obtained from Cancer Cell Line Encyclopedia (CCLE)36. Drugs,-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
names. Gene expression data of cell lines are obtained from Cancer Cell Line Encyclopedia CCLE 36 . Drugs,names. Gene expression data of cell lines are obtained from Cancer Cell Line Encyclopedia (CCLE)36. Drugs,names are retrieved in PubChem database 37 to obtain their SMILES vectors. Then the SMILES vectors are,names are retrieved in PubChem database37 to obtain their SMILES vectors. Then the SMILES vectors are,-0.11,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
names are retrieved in PubChem database 37 to obtain their SMILES vectors. Then the SMILES vectors are,names are retrieved in PubChem database37 to obtain their SMILES vectors. Then the SMILES vectors are,converted into molecular graphs with RDKit library 38 .,converted into molecular graphs with RDKit library38.,-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
converted into molecular graphs with RDKit library 38 .,converted into molecular graphs with RDKit library38.,We combine the GDSC and CCLE datasets by selecting cell lines whose drug responses and gene expression,We combine the GDSC and CCLE datasets by selecting cell lines whose drug responses and gene expression,-0.11,12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,3,3,0
We combine the GDSC and CCLE datasets by selecting cell lines whose drug responses and gene expression,We combine the GDSC and CCLE datasets by selecting cell lines whose drug responses and gene expression,"profiles are both recorded. In total, there are 223 drugs and 700 cell lines. After removing missing screening of","profiles are both recorded. In total, there are 223 drugs and 700 cell lines. After removing missing screening of",-0.11,-12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"profiles are both recorded. In total, there are 223 drugs and 700 cell lines. After removing missing screening of","profiles are both recorded. In total, there are 223 drugs and 700 cell lines. After removing missing screening of","drug responses, 133,212 pairs of data points are left for experiments. Each cell line is depicted by a transcriptomic","drug responses, 133,212 pairs of data points are left for experiments. Each cell line is depicted by a transcriptomic",-0.11,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"drug responses, 133,212 pairs of data points are left for experiments. Each cell line is depicted by a transcriptomic","drug responses, 133,212 pairs of data points are left for experiments. Each cell line is depicted by a transcriptomic","profile of 13,142 genes. In order to reduce the dimensionality of the input features to avoid potential over-fitting","profile of 13,142 genes. In order to reduce the dimensionality of the input features to avoid potential over-fitting",-0.11,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"profile of 13,142 genes. In order to reduce the dimensionality of the input features to avoid potential over-fitting","profile of 13,142 genes. In order to reduce the dimensionality of the input features to avoid potential over-fitting","in model training, we refer to the connectivity map proposed in LINCS L1000 research 39, and preserve only the","in model training, we refer to the connectivity map proposed in LINCS L1000 research39, and preserve only the",-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"in model training, we refer to the connectivity map proposed in LINCS L1000 research 39, and preserve only the","in model training, we refer to the connectivity map proposed in LINCS L1000 research39, and preserve only the","expression values of the 956 landmark genes, since it is testified that the expression pattern of other genes can be","expression values of the 956 landmark genes, since it is testified that the expression pattern of other genes can be",-0.11,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"expression values of the 956 landmark genes, since it is testified that the expression pattern of other genes can be","expression values of the 956 landmark genes, since it is testified that the expression pattern of other genes can be",precisely inferred by the landmark genes.,precisely inferred by the landmark genes.,-0.11,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
precisely inferred by the landmark genes.,precisely inferred by the landmark genes.,Drug representation,Drug representation,0.37,0,1,0,0,9,10,1,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,3,3,0
Drug representation,Drug representation,Previous research have demonstrated that representing drugs with molecular graphs provides better predictive,Previous research have demonstrated that representing drugs with molecular graphs provides better predictive,-0.07,0,1,0,0,10,9,-1,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,3,3,0
Previous research have demonstrated that representing drugs with molecular graphs provides better predictive,Previous research have demonstrated that representing drugs with molecular graphs provides better predictive,"power than compressed representations such as SMILES 11,25, since the structural information of a molecule can","power than compressed representations such as SMILES11,25, since the structural information of a molecule can",-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"power than compressed representations such as SMILES 11,25, since the structural information of a molecule can","power than compressed representations such as SMILES11,25, since the structural information of a molecule can","be naturally preserved in a graph. Specifically, by considering the atoms in a molecule as nodes and the chemical","be naturally preserved in a graph. Specifically, by considering the atoms in a molecule as nodes and the chemical",-0.11,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"be naturally preserved in a graph. Specifically, by considering the atoms in a molecule as nodes and the chemical","be naturally preserved in a graph. Specifically, by considering the atoms in a molecule as nodes and the chemical","bonds between atoms as edges, an undirected unweighted graph is constructed to represent the drug molecule.","bonds between atoms as edges, an undirected unweighted graph is constructed to represent the drug molecule.",-0.11,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"bonds between atoms as edges, an undirected unweighted graph is constructed to represent the drug molecule.","bonds between atoms as edges, an undirected unweighted graph is constructed to represent the drug molecule.","From the molecular graphs, node features proposed by DeepChem 40 such as atom symbol, atom degree, etc.,","From the molecular graphs, node features proposed by DeepChem40 such as atom symbol, atom degree, etc.,",-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,3,3,1
"From the molecular graphs, node features proposed by DeepChem 40 such as atom symbol, atom degree, etc.,","From the molecular graphs, node features proposed by DeepChem40 such as atom symbol, atom degree, etc.,",can be extracted.,can be extracted.,-0.11,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
can be extracted.,can be extracted.,"In this chapter, we further enhance the predictive power of a drugs graph representation by incorporating","In this chapter, we further enhance the predictive power of a drugs graph representation by incorporating",-0.11,12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,3,3,0
"In this chapter, we further enhance the predictive power of a drugs graph representation by incorporating","In this chapter, we further enhance the predictive power of a drugs graph representation by incorporating","properer node and edge features. In the previous work 25, there are five types of node features, i.e., atom","properer node and edge features. In the previous work25, there are five types of node features, i.e., atom",-0.11,-12,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"properer node and edge features. In the previous work 25, there are five types of node features, i.e., atom","properer node and edge features. In the previous work25, there are five types of node features, i.e., atom","symbol, atom degree, the total number of Hydrogen, implicit value of atom, and whether the atom is aromatic.","symbol, atom degree, the total number of Hydrogen, implicit value of atom, and whether the atom is aromatic.",-0.11,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"symbol, atom degree, the total number of Hydrogen, implicit value of atom, and whether the atom is aromatic.","symbol, atom degree, the total number of Hydrogen, implicit value of atom, and whether the atom is aromatic.","Nevertheless, these features are intuitively restricted to depict an atom in a molecule. Inspired by the Morgan","Nevertheless, these features are intuitively restricted to depict an atom in a molecule. Inspired by the Morgan",-0.11,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,3,3,1
"Nevertheless, these features are intuitively restricted to depict an atom in a molecule. Inspired by the Morgan","Nevertheless, these features are intuitively restricted to depict an atom in a molecule. Inspired by the Morgan","Algorithm and Extended-Connectivity Fingerprints ECFP 15, we present a circular algorithm to compute the","Algorithm and Extended-Connectivity Fingerprints (ECFP)15, we present a circular algorithm to compute the",-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,3,3,1
"Algorithm and Extended-Connectivity Fingerprints ECFP 15, we present a circular algorithm to compute the","Algorithm and Extended-Connectivity Fingerprints (ECFP)15, we present a circular algorithm to compute the","feature of an atom, considering both the atom itself and its surrounding environment.","feature of an atom, considering both the atom itself and its surrounding environment.",-0.11,0,1,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"feature of an atom, considering both the atom itself and its surrounding environment.","feature of an atom, considering both the atom itself and its surrounding environment.",Algorithm 1 . Circular atomic feature computation,Algorithm 1.  Circular atomic feature computation,17.12,0,1,1,0,9,9,0,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,3,3,0
Algorithm 1 . Circular atomic feature computation,Algorithm 1.  Circular atomic feature computation,"In Circular Atomic Feature Computation Algorithm 1, F i refers to the chemical properties of atom i to","In Circular Atomic Feature Computation Algorithm 1, Fi refers to the chemical properties of atom i to",0.82,12,0,0,1,9,9,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,3,3,0
"In Circular Atomic Feature Computation Algorithm 1, F i refers to the chemical properties of atom i to","In Circular Atomic Feature Computation Algorithm 1, Fi refers to the chemical properties of atom i to","be encoded, which involves the seven Daylight atomic invariants as the initial chemical properties, including","be encoded, which involves the seven Daylight atomic invariants as the initial chemical properties, including",-0.11,-12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"be encoded, which involves the seven Daylight atomic invariants as the initial chemical properties, including","be encoded, which involves the seven Daylight atomic invariants as the initial chemical properties, including","number of immediate neighbors who are non-hydrogen atoms, the valence minus the number of hydrogens","number of immediate neighbors who are non-hydrogen atoms, the valence minus the number of hydrogens",-0.11,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"number of immediate neighbors who are non-hydrogen atoms, the valence minus the number of hydrogens","number of immediate neighbors who are non-hydrogen atoms, the valence minus the number of hydrogens","meaning total bond order ignoring bonds to hydrogens, the atomic number, the atomic mass, the atomic","(meaning total bond order ignoring bonds to hydrogens), the atomic number, the atomic mass, the atomic",-0.11,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"meaning total bond order ignoring bonds to hydrogens, the atomic number, the atomic mass, the atomic","(meaning total bond order ignoring bonds to hydrogens), the atomic number, the atomic mass, the atomic","charge, the number of attached hydrogens, and aromaticity. X i r  denotes the identifier of atom  i  after collecting","charge, the number of attached hydrogens, and aromaticity. Xr",-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
"charge, the number of attached hydrogens, and aromaticity. X i r  denotes the identifier of atom  i  after collecting","charge, the number of attached hydrogens, and aromaticity. Xr",features from its r -hop neighbour atoms. h is the hashing function used for feature compression and binary is,features from its r-hop neighbour atoms. h is the hashing function used for feature compression and binary is,-0.11,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
features from its r -hop neighbour atoms. h is the hashing function used for feature compression and binary is,features from its r-hop neighbour atoms. h is the hashing function used for feature compression and binary is,the function to convert hashed integers back to binary features. Operator ? refers to the concatenation operation.,the function to convert hashed integers back to binary features. Operator ? refers to the concatenation operation.,-0.11,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,3,3,1
the function to convert hashed integers back to binary features. Operator ? refers to the concatenation operation.,the function to convert hashed integers back to binary features. Operator ? refers to the concatenation operation.,Scientific Reports 2025 15:179 https://doi.org/10.1038/s41598-024-83090-3 3,| https://doi.org/10.1038/s41598-024-83090-3,1.18,69.94,0,1,1,9,8,-1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,3,3,1
Figure 2 provides an example of the feature extraction procedure of atom 2 in the Butyramide molecule,Figure 2 provides an example of the feature extraction procedure of atom 2 in the Butyramide molecule,"considering interested radius of 1. In particular, this algorithm involves three stages:","considering interested radius of 1. In particular, this algorithm involves three stages:",-0.34,-12,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"considering interested radius of 1. In particular, this algorithm involves three stages:","considering interested radius of 1. In particular, this algorithm involves three stages:",1. Initial Stage: Each atom in the molecule is assigned with a unique integer identifier which is generated by,"1.	 Initial Stage: Each atom in the molecule is assigned with a unique integer identifier which is generated by",1,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,4,4,0
1. Initial Stage: Each atom in the molecule is assigned with a unique integer identifier which is generated by,"1.	 Initial Stage: Each atom in the molecule is assigned with a unique integer identifier which is generated by",hashing a set of chemical properties.,hashing a set of chemical properties.,-0.34,12.98,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
hashing a set of chemical properties.,hashing a set of chemical properties.,"2. Updating Stage: After initialization, each atoms identifier will be updated iteratively. Starting by radius","2.	 Updating Stage: After initialization, each atoms identifier will be updated iteratively. Starting by radius r = 1:",-0.34,-12.98,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,4,4,0
"2. Updating Stage: After initialization, each atoms identifier will be updated iteratively. Starting by radius","2.	 Updating Stage: After initialization, each atoms identifier will be updated iteratively. Starting by radius r = 1:",a An array will be formed by collecting the radius and the core atoms current identifier.,"(a)	 An array will be formed by collecting the radius and the core atoms current identifier.",1,14,0,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,0
a An array will be formed by collecting the radius and the core atoms current identifier.,"(a)	 An array will be formed by collecting the radius and the core atoms current identifier.","b Next, the neighboring information of the atom that is r hops away from the core atom will be incorpo­","(b)	 Next, the neighboring information of the atom that is r hops away from the core atom will be incorpo­",-0.34,-0.62,1,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,4,4,1
"b Next, the neighboring information of the atom that is r hops away from the core atom will be incorpo­","(b)	 Next, the neighboring information of the atom that is r hops away from the core atom will be incorpo­","rated into the array. Ranked by the bond order single, double, triple, and aromatic, the bond order and","rated into the array. Ranked by the bond order (single, double, triple, and aromatic), the bond order and",-0.34,17.18,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"rated into the array. Ranked by the bond order single, double, triple, and aromatic, the bond order and","rated into the array. Ranked by the bond order (single, double, triple, and aromatic), the bond order and",the current identifier of the interested atom are appended to the array.,the current identifier of the interested atom are appended to the array.,-0.34,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
the current identifier of the interested atom are appended to the array.,the current identifier of the interested atom are appended to the array.,c Then the same hash function used in the initial stage is applied again to convert the array into a new,"(c)	 Then the same hash function used in the initial stage is applied again to convert the array into a new",-0.34,-16.41,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,4,4,1
c Then the same hash function used in the initial stage is applied again to convert the array into a new,"(c)	 Then the same hash function used in the initial stage is applied again to convert the array into a new",integer identifier.,integer identifier.,-0.34,16.41,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
integer identifier.,integer identifier.,d The above procedure is repeated for each atom in the molecule.,"(d)	 The above procedure is repeated for each atom in the molecule.",-0.34,-17.36,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,4,4,1
d The above procedure is repeated for each atom in the molecule.,"(d)	 The above procedure is repeated for each atom in the molecule.",e The radius will be updated as r := r + 1 and another iteration to update identifiers for all atoms will be,"(e)	 The radius will be updated as r := r + 1 and another iteration to update identifiers for all atoms will be",-0.34,0.93,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,4,4,1
e The radius will be updated as r := r + 1 and another iteration to update identifiers for all atoms will be,"(e)	 The radius will be updated as r := r + 1 and another iteration to update identifiers for all atoms will be","started, unless r has already met the users interested radius.","started, unless r has already met the users interested radius.",-0.34,16.43,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"started, unless r has already met the users interested radius.","started, unless r has already met the users interested radius.","3. Reduction Stage: Eventually, for each atom, all the identifiers ever generated in the updating stage are con­","3.	 Reduction Stage: Eventually, for each atom, all the identifiers ever generated in the updating stage are con­",1,-30.56,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,4,4,0
"3. Reduction Stage: Eventually, for each atom, all the identifiers ever generated in the updating stage are con­","3.	 Reduction Stage: Eventually, for each atom, all the identifiers ever generated in the updating stage are con­",verted into a 64-bit binary vector by calculating the modulus of the decimal integer and concatenated to,verted into a 64-bit binary vector by calculating the modulus of the decimal integer and concatenated to,-0.34,12.98,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
verted into a 64-bit binary vector by calculating the modulus of the decimal integer and concatenated to,verted into a 64-bit binary vector by calculating the modulus of the decimal integer and concatenated to,"form the final atom feature vector of length 64 × radius + 1 .In the typical ECFP algorithm, the updating","form the final atom feature vector of length 64 × (radius + 1).In the typical ECFP algorithm, the updating",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"form the final atom feature vector of length 64 × radius + 1 .In the typical ECFP algorithm, the updating","form the final atom feature vector of length 64 × (radius + 1).In the typical ECFP algorithm, the updating","stage is aimed at discovering the unique substructures in the molecule, which will be consequently integrated","stage is aimed at discovering the unique substructures in the molecule, which will be consequently integrated",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"stage is aimed at discovering the unique substructures in the molecule, which will be consequently integrated","stage is aimed at discovering the unique substructures in the molecule, which will be consequently integrated","into the fingerprint serving as a molecular-level representation. Thus, after the updating iterations, there will","into the fingerprint serving as a molecular-level representation. Thus, after the updating iterations, there will",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"into the fingerprint serving as a molecular-level representation. Thus, after the updating iterations, there will","into the fingerprint serving as a molecular-level representation. Thus, after the updating iterations, there will",be a duplicate structure removal stage to eliminate the identical features which encapsulates the same sur­,be a duplicate structure removal stage to eliminate the identical features which encapsulates the same sur­,-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
be a duplicate structure removal stage to eliminate the identical features which encapsulates the same sur­,be a duplicate structure removal stage to eliminate the identical features which encapsulates the same sur­,"rounding environment of atoms. However, on the contrary to a molecular-level representation, in our case","rounding environment of atoms. However, on the contrary to a molecular-level representation, in our case",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"rounding environment of atoms. However, on the contrary to a molecular-level representation, in our case","rounding environment of atoms. However, on the contrary to a molecular-level representation, in our case",we require an atom-level feature where the structural duplication amongst atoms is not hampering feature,we require an atom-level feature where the structural duplication amongst atoms is not hampering feature,-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
we require an atom-level feature where the structural duplication amongst atoms is not hampering feature,we require an atom-level feature where the structural duplication amongst atoms is not hampering feature,"reduction. Besides, the original algorithm only considers the last generated identifiers upon reducing them","reduction. Besides, the original algorithm only considers the last generated identifiers upon reducing them",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"reduction. Besides, the original algorithm only considers the last generated identifiers upon reducing them","reduction. Besides, the original algorithm only considers the last generated identifiers upon reducing them","into the fingerprint, which is effective in producing the unique fingerprint of the molecule, whereas we pre­","into the fingerprint, which is effective in producing the unique fingerprint of the molecule, whereas we pre­",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"into the fingerprint, which is effective in producing the unique fingerprint of the molecule, whereas we pre­","into the fingerprint, which is effective in producing the unique fingerprint of the molecule, whereas we pre­",serve all the ever-generated identifiers to produce the atom-level features. This is because the last identifier is,serve all the ever-generated identifiers to produce the atom-level features. This is because the last identifier is,-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
serve all the ever-generated identifiers to produce the atom-level features. This is because the last identifier is,serve all the ever-generated identifiers to produce the atom-level features. This is because the last identifier is,always computed considering a relatively large radius. The surrounding substructure might thus be identical,always computed considering a relatively large radius. The surrounding substructure might thus be identical,-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
always computed considering a relatively large radius. The surrounding substructure might thus be identical,always computed considering a relatively large radius. The surrounding substructure might thus be identical,"for different atoms. Therefore, if merely considering the last identifier, certain atom-level features may be","for different atoms. Therefore, if merely considering the last identifier, certain atom-level features may be",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"for different atoms. Therefore, if merely considering the last identifier, certain atom-level features may be","for different atoms. Therefore, if merely considering the last identifier, certain atom-level features may be","duplicated, and the corresponding atoms will be indistinguishable. Under such circumstances, identifiers","duplicated, and the corresponding atoms will be indistinguishable. Under such circumstances, identifiers",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"duplicated, and the corresponding atoms will be indistinguishable. Under such circumstances, identifiers","duplicated, and the corresponding atoms will be indistinguishable. Under such circumstances, identifiers",generated at all radius levels are appended to form the atom-level feature.,generated at all radius levels are appended to form the atom-level feature.,-0.34,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
generated at all radius levels are appended to form the atom-level feature.,generated at all radius levels are appended to form the atom-level feature.,"Fig. 2 . Illustration of feature extraction procedure of atom 2 in the Butyramide molecule. In the initial stage,","Fig. 2.  Illustration of feature extraction procedure of atom 2 in the Butyramide molecule. In the initial stage,",43.22,-12.98,0,1,0,9,9,0,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,4,4,0
"Fig. 2 . Illustration of feature extraction procedure of atom 2 in the Butyramide molecule. In the initial stage,","Fig. 2.  Illustration of feature extraction procedure of atom 2 in the Butyramide molecule. In the initial stage,","chemical features including number of non-hydrogen neibours, valency, atomic number, etc., are extracted","chemical features including number of non-hydrogen neibours, valency, atomic number, etc., are extracted",-0.34,0,1,0,0,9,9,0,0,1,0,0,0,0,0,0,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"chemical features including number of non-hydrogen neibours, valency, atomic number, etc., are extracted","chemical features including number of non-hydrogen neibours, valency, atomic number, etc., are extracted","and hashed to compute the initial identifier of each atom. In the update stage, starting from radius of 1, the","and hashed to compute the initial identifier of each atom. In the update stage, starting from radius of 1, the",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"and hashed to compute the initial identifier of each atom. In the update stage, starting from radius of 1, the","and hashed to compute the initial identifier of each atom. In the update stage, starting from radius of 1, the","bond orders and identifiers of the surrounding atoms atom 3, 6 and 1 are combined and concatenated with","bond orders and identifiers of the surrounding atoms (atom 3, 6 and 1) are combined and concatenated with",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"bond orders and identifiers of the surrounding atoms atom 3, 6 and 1 are combined and concatenated with","bond orders and identifiers of the surrounding atoms (atom 3, 6 and 1) are combined and concatenated with",the iteration number and the initial identifier of the focused atom atom 2. The hash function is applied again,the iteration number and the initial identifier of the focused atom (atom 2). The hash function is applied again,-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
the iteration number and the initial identifier of the focused atom atom 2. The hash function is applied again,the iteration number and the initial identifier of the focused atom (atom 2). The hash function is applied again,"on the concatenated feature to form the new identifier. Finally, in the reduction stage, each of the identifiers of","on the concatenated feature to form the new identifier. Finally, in the reduction stage, each of the identifiers of",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"on the concatenated feature to form the new identifier. Finally, in the reduction stage, each of the identifiers of","on the concatenated feature to form the new identifier. Finally, in the reduction stage, each of the identifiers of",atom 2 generated in the update stage are converted to a 64-bit binary vector and concatenated to form the final,atom 2 generated in the update stage are converted to a 64-bit binary vector and concatenated to form the final,-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
atom 2 generated in the update stage are converted to a 64-bit binary vector and concatenated to form the final,atom 2 generated in the update stage are converted to a 64-bit binary vector and concatenated to form the final,"atom feature. In our implementation, we combined the binary vectors of radius 0, 1, 2 and 3, which forms a the","atom feature. In our implementation, we combined the binary vectors of radius 0, 1, 2 and 3, which forms a the",-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
"atom feature. In our implementation, we combined the binary vectors of radius 0, 1, 2 and 3, which forms a the","atom feature. In our implementation, we combined the binary vectors of radius 0, 1, 2 and 3, which forms a the",final feature vector of length,final feature vector of length 4 × 64 = 256.,-0.34,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,4,4,1
final feature vector of length,final feature vector of length 4 × 64 = 256.,Scientific Reports 2025 15:179 https://doi.org/10.1038/s41598-024-83090-3 4,| https://doi.org/10.1038/s41598-024-83090-3,3.62,69.94,0,0,1,9,8,-1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,4,4,1
Computational framework,Computational framework,We utilize Graph Neural Networks GNN to learn the latent features of drugs molecular graphs and,We utilize Graph Neural Networks (GNN) to learn the latent features of drugs molecular graphs and,-0.07,0,1,0,0,10,9,-1,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,5,5,0
We utilize Graph Neural Networks GNN to learn the latent features of drugs molecular graphs and,We utilize Graph Neural Networks (GNN) to learn the latent features of drugs molecular graphs and,"Convolutional Neural Networks CNN to learn the representation of the gene expression data, and combine","Convolutional Neural Networks (CNN) to learn the representation of the gene expression data, and combine",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,5,5,1
"Convolutional Neural Networks CNN to learn the representation of the gene expression data, and combine","Convolutional Neural Networks (CNN) to learn the representation of the gene expression data, and combine",them together to predict the response level as shown in Fig. 1. Instead of concatenating latent features of drug,them together to predict the response level as shown in Fig. 1. Instead of concatenating latent features of drug,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
them together to predict the response level as shown in Fig. 1. Instead of concatenating latent features of drug,them together to predict the response level as shown in Fig. 1. Instead of concatenating latent features of drug,"and cell line as tCNN 11 and GraphDRP 25, we propose to leverage multi-head attention mechanism introduced","and cell line as tCNN11 and GraphDRP25, we propose to leverage multi-head attention mechanism introduced",-0.12,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"and cell line as tCNN 11 and GraphDRP 25, we propose to leverage multi-head attention mechanism introduced","and cell line as tCNN11 and GraphDRP25, we propose to leverage multi-head attention mechanism introduced",by Transformer 41 to integrate the drug and cell line features effectively.,by Transformer41 to integrate the drug and cell line features effectively.,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
by Transformer 41 to integrate the drug and cell line features effectively.,by Transformer41 to integrate the drug and cell line features effectively.,Each head H i in the multi-head attention module can be formulated as,Each head Hi in the multi-head attention module can be formulated as,-0.12,12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,5,5,0
Each head H i in the multi-head attention module can be formulated as,Each head Hi in the multi-head attention module can be formulated as,"where Q, K and V stand for the query, key and value used in an attention layer. To obtain the drug embed","where Q, K and V stand for the query, key and value used in an attention layer. To obtain the drug embed",1.58,-12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,0
"where Q, K and V stand for the query, key and value used in an attention layer. To obtain the drug embed","where Q, K and V stand for the query, key and value used in an attention layer. To obtain the drug embed","influenced by gene expressions, we use drug features encoded by GNN as Q and cell line features encoded by","influenced by gene expressions, we use drug features encoded by GNN as Q and cell line features encoded by",-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"influenced by gene expressions, we use drug features encoded by GNN as Q and cell line features encoded by","influenced by gene expressions, we use drug features encoded by GNN as Q and cell line features encoded by","CNN as K and V . On the contrary, to learn the gene embed, we use cell line features as Q and drug features as K","CNN as K and V. On the contrary, to learn the gene embed, we use cell line features as Q and drug features as K",-0.12,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,5,5,1
"CNN as K and V . On the contrary, to learn the gene embed, we use cell line features as Q and drug features as K","CNN as K and V. On the contrary, to learn the gene embed, we use cell line features as Q and drug features as K","and V . Eventually, the integrative features are combined and fed into a predictor composed of a dense layer for","and V. Eventually, the integrative features are combined and fed into a predictor composed of a dense layer for",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"and V . Eventually, the integrative features are combined and fed into a predictor composed of a dense layer for","and V. Eventually, the integrative features are combined and fed into a predictor composed of a dense layer for",drug response prediction.,drug response prediction.,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
drug response prediction.,drug response prediction.,"After developing the model, we adopt Integrated Gradients 34 and GNNExplainer 33 to explore the saliency of","After developing the model, we adopt Integrated Gradients34 and GNNExplainer33 to explore the saliency of",1,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,5,5,0
"After developing the model, we adopt Integrated Gradients 34 and GNNExplainer 33 to explore the saliency of","After developing the model, we adopt Integrated Gradients34 and GNNExplainer33 to explore the saliency of","inputs, i.e., atoms and bonds of the drug molecule and transcriptomic features of the cell line, which reveals the","inputs, i.e., atoms and bonds of the drug molecule and transcriptomic features of the cell line, which reveals the",-0.12,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"inputs, i.e., atoms and bonds of the drug molecule and transcriptomic features of the cell line, which reveals the","inputs, i.e., atoms and bonds of the drug molecule and transcriptomic features of the cell line, which reveals the",reaction mechanism of cancer cell lines and drugs.,reaction mechanism of cancer cell lines and drugs.,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
reaction mechanism of cancer cell lines and drugs.,reaction mechanism of cancer cell lines and drugs.,Graph neural networks GNN,Graph neural networks (GNN),0.41,0,1,0,0,9,10,1,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,5,5,0
Graph neural networks GNN,Graph neural networks (GNN),"After constructing the molecular graphs and extracting atom-level features for the drugs, we develop GNN","After constructing the molecular graphs and extracting atom-level features for the drugs, we develop GNN",-0.07,0,1,0,0,10,9,-1,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,5,5,0
"After constructing the molecular graphs and extracting atom-level features for the drugs, we develop GNN","After constructing the molecular graphs and extracting atom-level features for the drugs, we develop GNN","models to further learn the latent representation of the drugs. In this work, we take advantage of four types of","models to further learn the latent representation of the drugs. In this work, we take advantage of four types of",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"models to further learn the latent representation of the drugs. In this work, we take advantage of four types of","models to further learn the latent representation of the drugs. In this work, we take advantage of four types of",GNN models and compare their performance in drug response and mechanism prediction: Graph Convolutional,GNN models and compare their performance in drug response and mechanism prediction: Graph Convolutional,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,5,5,1
GNN models and compare their performance in drug response and mechanism prediction: Graph Convolutional,GNN models and compare their performance in drug response and mechanism prediction: Graph Convolutional,"Networks GCN 42, Graph Attention Networks GAT 43, Relational Graph Convolutional Networks RGCN 44,","Networks (GCN)42, Graph Attention Networks (GAT)43, Relational Graph Convolutional Networks (RGCN)44,",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,5,5,1
"Networks GCN 42, Graph Attention Networks GAT 43, Relational Graph Convolutional Networks RGCN 44,","Networks (GCN)42, Graph Attention Networks (GAT)43, Relational Graph Convolutional Networks (RGCN)44,","and Relational Graph Attention Networks RGAT 45 . Similarly, the idea for such GNN models is to aggregate the","and Relational Graph Attention Networks (RGAT)45. Similarly, the idea for such GNN models is to aggregate the",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"and Relational Graph Attention Networks RGAT 45 . Similarly, the idea for such GNN models is to aggregate the","and Relational Graph Attention Networks (RGAT)45. Similarly, the idea for such GNN models is to aggregate the",information from a node itself and its neighborhood.,information from a node itself and its neighborhood.,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
information from a node itself and its neighborhood.,information from a node itself and its neighborhood.,"If we define the atom set in a drugs molecule as V and the bond set as E, the molecular graph of this drug can","If we define the atom set in a drugs molecule as V and the bond set as E, the molecular graph of this drug can",-0.12,12,0,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,5,5,0
"If we define the atom set in a drugs molecule as V and the bond set as E, the molecular graph of this drug can","If we define the atom set in a drugs molecule as V and the bond set as E, the molecular graph of this drug can","be given by G =  V, E  . Then we use an adjacent binary matrix A ? R N ×N to represent the edge connection","be given by G = (V, E). Then we use an adjacent binary matrix A ?RN×N to represent the edge connection",-0.12,-12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"be given by G =  V, E  . Then we use an adjacent binary matrix A ? R N ×N to represent the edge connection","be given by G = (V, E). Then we use an adjacent binary matrix A ?RN×N to represent the edge connection","between nodes where N is the number of atoms, a i,j = 1 denotes a connection between node i and j, and a i,j = 0","between nodes where N is the number of atoms, ai,j = 1 denotes a connection between node i and j, and ai,j = 0",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"between nodes where N is the number of atoms, a i,j = 1 denotes a connection between node i and j, and a i,j = 0","between nodes where N is the number of atoms, ai,j = 1 denotes a connection between node i and j, and ai,j = 0","denotes no connection. Additionally, a feature matrix X ? R N ×M is used for representing the node features of","denotes no connection. Additionally, a feature matrix X ?RN×M is used for representing the node features of",-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"denotes no connection. Additionally, a feature matrix X ? R N ×M is used for representing the node features of","denotes no connection. Additionally, a feature matrix X ?RN×M is used for representing the node features of",atoms where M is the dimension of feature vector that has been extracted by the algorithm aforementioned.,atoms where M is the dimension of feature vector that has been extracted by the algorithm aforementioned.,-0.12,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
atoms where M is the dimension of feature vector that has been extracted by the algorithm aforementioned.,atoms where M is the dimension of feature vector that has been extracted by the algorithm aforementioned.,The GCN layer is defined by,The GCN layer is defined by,-0.12,12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,5,5,0
The GCN layer is defined by,The GCN layer is defined by,a ij,aij,0.37,203.68,0,0,0,9,9.96,0.96,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,0
a ij,aij,h i = W,hi = W,-0.16,-77.59,0,0,1,9.96,8.97,-1,0,0,0,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,5,5,1
h i = W,hi = W,j?N i ? {i},{i},0.39,57.32,0,1,0,8.97,5.98,-2.99,0,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
j?N i ? {i},{i},"denotes the node feature vector, W is the weight matrix, and N i is the neighbor node set of node i .","denotes the node feature vector, W is the weight matrix, and Ni is the neighbor node set of node i.",1.38,-195.41,0,0,0,5.98,9,3.02,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,5,5,0
"denotes the node feature vector, W is the weight matrix, and N i is the neighbor node set of node i .","denotes the node feature vector, W is the weight matrix, and Ni is the neighbor node set of node i.","For the GAT layer, the attention coefficient of node i and j is defined as e i,j = a  Wx i , Wx j  according to 43, and","For the GAT layer, the attention coefficient of node i and j is defined as ei,j = a(Wxi, Wxj) according to43, and",1,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,5,5,0
"For the GAT layer, the attention coefficient of node i and j is defined as e i,j = a  Wx i , Wx j  according to 43, and","For the GAT layer, the attention coefficient of node i and j is defined as ei,j = a(Wxi, Wxj) according to43, and",is only computed when node j is in the neighborhood of node i . Then the GAT layer can be given by,is only computed when node j is in the neighborhood of node i. Then the GAT layer can be given by,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
is only computed when node j is in the neighborhood of node i . Then the GAT layer can be given by,is only computed when node j is in the neighborhood of node i. Then the GAT layer can be given by,"h i = a i,i Wx i + ?","hi = ai,iWxi +",0.61,133.71,0,0,1,9,8.97,-0.03,0,0,0,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,5,5,0
"h i = a i,i Wx i + ?","hi = ai,iWxi +",j?N i,j?Ni,-5.98,36.65,0,1,1,8.97,5.98,-2.99,0,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
j?N i,j?Ni,"a i,j Wx j 3","ai,jWxj",5.14,44.75,0,1,0,5.98,8.97,2.99,0,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"a i,j Wx j 3","ai,jWxj","where x i is the node feature vector, W is the weight matrix, N i is the neighbor node set of node i, and a i,j is the","where xi is the node feature vector, W is the weight matrix, Ni is the neighbor node set of node i, and ai,j is the",1.21,-215.11,0,0,0,8.97,9,0.03,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,5,5,0
"where x i is the node feature vector, W is the weight matrix, N i is the neighbor node set of node i, and a i,j is the","where xi is the node feature vector, W is the weight matrix, Ni is the neighbor node set of node i, and ai,j is the",normalized attention coefficients with softmax function.,normalized attention coefficients with softmax function.,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
normalized attention coefficients with softmax function.,normalized attention coefficients with softmax function.,"Notably, one drawback when adopting the typical GCN and GAT layers on molecular graphs is that they both","Notably, one drawback when adopting the typical GCN and GAT layers on molecular graphs is that they both",1,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,5,5,0
"Notably, one drawback when adopting the typical GCN and GAT layers on molecular graphs is that they both","Notably, one drawback when adopting the typical GCN and GAT layers on molecular graphs is that they both",dismiss the edge properties of the graph whereas the varying chemical bond types in a molecule could also,dismiss the edge properties of the graph whereas the varying chemical bond types in a molecule could also,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
dismiss the edge properties of the graph whereas the varying chemical bond types in a molecule could also,dismiss the edge properties of the graph whereas the varying chemical bond types in a molecule could also,"impose a crucial impact on the drugs functional mechanism. In order to tackle this problem, we encode the","impose a crucial impact on the drugs functional mechanism. In order to tackle this problem, we encode the",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"impose a crucial impact on the drugs functional mechanism. In order to tackle this problem, we encode the","impose a crucial impact on the drugs functional mechanism. In order to tackle this problem, we encode the","chemical bond type single, double, triple, and aromatic into the edge features, which can be used for updating","chemical bond type (single, double, triple, and aromatic) into the edge features, which can be used for updating",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"chemical bond type single, double, triple, and aromatic into the edge features, which can be used for updating","chemical bond type (single, double, triple, and aromatic) into the edge features, which can be used for updating",edges in the message passing procedure in GNN models. Edge features are directly supported by GAT layer and,edges in the message passing procedure in GNN models. Edge features are directly supported by GAT layer and,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
edges in the message passing procedure in GNN models. Edge features are directly supported by GAT layer and,edges in the message passing procedure in GNN models. Edge features are directly supported by GAT layer and,GATv2 layer which is designed to fix the static attention problem of original GAT layer 46,GATv2 layer which is designed to fix the static attention problem of original GAT layer46.,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,5,5,1
GATv2 layer which is designed to fix the static attention problem of original GAT layer 46,GATv2 layer which is designed to fix the static attention problem of original GAT layer46.,"To further investigate the effectiveness of edge features, we look into RGCN and RGAT models, which","To further investigate the effectiveness of edge features, we look into RGCN and RGAT models, which",-0.12,12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,5,5,0
"To further investigate the effectiveness of edge features, we look into RGCN and RGAT models, which","To further investigate the effectiveness of edge features, we look into RGCN and RGAT models, which",consider edge types as relations and differentiate the message passing patterns according to various relation,consider edge types as relations and differentiate the message passing patterns according to various relation,-0.12,-12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
consider edge types as relations and differentiate the message passing patterns according to various relation,consider edge types as relations and differentiate the message passing patterns according to various relation,"types. In molecular graphs, edges represent chemical bonds that naturally possess disparate characteristics","types. In molecular graphs, edges represent chemical bonds that naturally possess disparate characteristics",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"types. In molecular graphs, edges represent chemical bonds that naturally possess disparate characteristics","types. In molecular graphs, edges represent chemical bonds that naturally possess disparate characteristics","and should be treated accordingly. Therefore, we attempt to leverage RGCN and RGAT models to represent a","and should be treated accordingly. Therefore, we attempt to leverage RGCN and RGAT models to represent a",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"and should be treated accordingly. Therefore, we attempt to leverage RGCN and RGAT models to represent a","and should be treated accordingly. Therefore, we attempt to leverage RGCN and RGAT models to represent a","molecule more precisely. Considering there are R relations in total, the RGCN layer can be defined as","molecule more precisely. Considering there are R relations in total, the RGCN layer can be defined as",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
"molecule more precisely. Considering there are R relations in total, the RGCN layer can be defined as","molecule more precisely. Considering there are R relations in total, the RGCN layer can be defined as",h i = W  root  x i +,hi = W (root)xi +,0.68,108.79,0,0,1,9,8.97,-0.03,0,0,0,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,5,5,0
h i = W  root  x i +,hi = W (root)xi +,r?R,r?R,0.28,71.51,0,1,1,8.97,5.98,-2.99,0,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
r?R,r?R,j?N i  r,j?Ni,-11.24,17.8,0,1,0,5.98,5.98,0,1,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,5,5,1
j?N i  r,j?Ni,Scientific Reports 2025 15:179 https://doi.org/10.1038/s41598-024-83090-3 5,| https://doi.org/10.1038/s41598-024-83090-3,12.17,-128.16,0,0,1,5.98,8,2.02,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,5,5,0
"where N i  r  denotes the neighbor node set of node i under relation r . Unlike general GCN layer, RGCN layer","denotes the neighbor node set of node i under relation r. Unlike general GCN layer, RGCN layer","learns different weights specific to relation types. W  r  represents the weights corresponding to relation r, and","learns different weights specific to relation types. W (r) represents the weights corresponding to relation r, and",-0.2,-42.66,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"learns different weights specific to relation types. W  r  represents the weights corresponding to relation r, and","learns different weights specific to relation types. W (r) represents the weights corresponding to relation r, and",W  root  corresponds to a special self-connected relation that is not included in R .,W (root) corresponds to a special self-connected relation that is not included in R.,0,0,1,0,0,9,8.97,-0.03,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,6,6,1
W  root  corresponds to a special self-connected relation that is not included in R .,W (root) corresponds to a special self-connected relation that is not included in R.,"Similar to the way RGCN creates relation-specific transformations to update node representations, RGAT also","Similar to the way RGCN creates relation-specific transformations to update node representations, RGAT also",1.75,0,1,0,0,8.97,9,0.03,0,0,0,1,0,0,0,1,0,1,1,0,0,0,0,1,0,0,0,1,6,6,0
"Similar to the way RGCN creates relation-specific transformations to update node representations, RGAT also","Similar to the way RGCN creates relation-specific transformations to update node representations, RGAT also",proposes relation-specific attention weights for message aggregation. If we compute the attention coefficient of,proposes relation-specific attention weights for message aggregation. If we compute the attention coefficient of,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
proposes relation-specific attention weights for message aggregation. If we compute the attention coefficient of,proposes relation-specific attention weights for message aggregation. If we compute the attention coefficient of,h i =,hi =,2.41,145.56,0,0,1,9,8.97,-0.03,0,0,0,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,6,6,0
h i =,hi =,r?R,r?R,0.46,21.79,0,1,1,8.97,5.98,-2.99,0,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
r?R,r?R,j?N i  r,j?N(r),-0.3,14.89,0,1,1,5.98,5.98,0,1,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
j?N i  r,j?N(r),"i,j  r  x  j r","i,j",-1.66,29.81,0,1,0,5.98,5.98,0,1,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"i,j  r  x  j r","i,j",j  5,j ,-0.55,15.15,0,0,0,5.98,5.98,0,1,0,0,1,1,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
j  5,j ,"where N i  r  denotes the neighbor node set of node i under relation r and a i,j  r   is the normalized attention",denotes the neighbor node set of node i under relation r and a(r),2.36,-183.85,0,0,1,5.98,9,3.02,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,6,6,0
"where N i  r  denotes the neighbor node set of node i under relation r and a i,j  r   is the normalized attention",denotes the neighbor node set of node i under relation r and a(r),"coefficients with softmax function. Notably, the softmax function can be applied either over only attention","coefficients with softmax function. Notably, the softmax function can be applied either over only attention",0.15,-43.35,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"coefficients with softmax function. Notably, the softmax function can be applied either over only attention","coefficients with softmax function. Notably, the softmax function can be applied either over only attention","coefficients under single relation type or all attention coefficients regardless of relation types, which result in","coefficients under single relation type or all attention coefficients regardless of relation types, which result in",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"coefficients under single relation type or all attention coefficients regardless of relation types, which result in","coefficients under single relation type or all attention coefficients regardless of relation types, which result in","within-relation GAT WIRGAT and across-relation GAT ARGAT, respectively. In our experiments, ARGAT","within-relation GAT (WIRGAT) and across-relation GAT (ARGAT), respectively. In our experiments, ARGAT",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"within-relation GAT WIRGAT and across-relation GAT ARGAT, respectively. In our experiments, ARGAT","within-relation GAT (WIRGAT) and across-relation GAT (ARGAT), respectively. In our experiments, ARGAT",is found to outperform WIRGAT and is thereby used in the subsequent analysis.,is found to outperform WIRGAT and is thereby used in the subsequent analysis.,-0.2,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
is found to outperform WIRGAT and is thereby used in the subsequent analysis.,is found to outperform WIRGAT and is thereby used in the subsequent analysis.,"Hyperparameters such as the radius in atom feature extraction, number of neural network layers, hidden","Hyperparameters such as the radius in atom feature extraction, number of neural network layers, hidden",1.65,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,6,6,0
"Hyperparameters such as the radius in atom feature extraction, number of neural network layers, hidden","Hyperparameters such as the radius in atom feature extraction, number of neural network layers, hidden",sizes and dropout rates are searched to develop the best model. We first implemented GCN and GAT-based,sizes and dropout rates are searched to develop the best model. We first implemented GCN and GAT-based,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
sizes and dropout rates are searched to develop the best model. We first implemented GCN and GAT-based,sizes and dropout rates are searched to develop the best model. We first implemented GCN and GAT-based,"XGDP with the features extracted with radius of 0, 1, 2 and 3, and found radius of 3 obtained the best and","XGDP with the features extracted with radius of 0, 1, 2 and 3, and found radius of 3 obtained the best and",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,1
"XGDP with the features extracted with radius of 0, 1, 2 and 3, and found radius of 3 obtained the best and","XGDP with the features extracted with radius of 0, 1, 2 and 3, and found radius of 3 obtained the best and",most stable performace on the validation set. Grid search is then conducted to find the optimal parameters for,most stable performace on the validation set. Grid search is then conducted to find the optimal parameters for,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
most stable performace on the validation set. Grid search is then conducted to find the optimal parameters for,most stable performace on the validation set. Grid search is then conducted to find the optimal parameters for,"number of layers of both GNN and CNN in 1, 2, 3, 4, 5, hidden sizes in 128, 256, 512 and dropout rates in","number of layers of both GNN and CNN in [1, 2, 3, 4, 5], hidden sizes in [128, 256, 512] and dropout rates in",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"number of layers of both GNN and CNN in 1, 2, 3, 4, 5, hidden sizes in 128, 256, 512 and dropout rates in","number of layers of both GNN and CNN in [1, 2, 3, 4, 5], hidden sizes in [128, 256, 512] and dropout rates in","0, 0.1, 0.2, 0.3, 0.4, 0.5 . Finally, the number of layers is set to 2 for the GNN module and 3 for the CNN module.","[0, 0.1, 0.2, 0.3, 0.4, 0.5] . Finally, the number of layers is set to 2 for the GNN module and 3 for the CNN module.",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,1
"0, 0.1, 0.2, 0.3, 0.4, 0.5 . Finally, the number of layers is set to 2 for the GNN module and 3 for the CNN module.","[0, 0.1, 0.2, 0.3, 0.4, 0.5] . Finally, the number of layers is set to 2 for the GNN module and 3 for the CNN module.",The hidden size is set to 128. And the dropout rate is configured as 0.5.,The hidden size is set to 128. And the dropout rate is configured as 0.5.,-0.2,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,6,6,1
The hidden size is set to 128. And the dropout rate is configured as 0.5.,The hidden size is set to 128. And the dropout rate is configured as 0.5.,Model interpretability,Model interpretability,0.67,0,1,1,0,9,10,1,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,6,6,0
Model interpretability,Model interpretability,"To explore our proposed models interpretability, we leverage on GNNExplainer 33 to identify the functional","To explore our proposed models interpretability, we leverage on GNNExplainer33 to identify the functional",-0.12,0,1,0,1,10,9,-1,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,6,6,0
"To explore our proposed models interpretability, we leverage on GNNExplainer 33 to identify the functional","To explore our proposed models interpretability, we leverage on GNNExplainer33 to identify the functional",groups of molecular graphs and Integrated Gradients 34 implemented by Captum 47 to track the attributes of the,groups of molecular graphs and Integrated Gradients34 implemented by Captum47 to track the attributes of the,-0.2,0,1,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
groups of molecular graphs and Integrated Gradients 34 implemented by Captum 47 to track the attributes of the,groups of molecular graphs and Integrated Gradients34 implemented by Captum47 to track the attributes of the,genes in cancer cell line data.,genes in cancer cell line data.,-0.2,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
genes in cancer cell line data.,genes in cancer cell line data.,Integrated gradients,Integrated gradients,0.72,0,1,0,0,9,9,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,1,0,0,0,1,6,6,0
Integrated gradients,Integrated gradients,Integrated Gradients is a gradient-based attribution method proposed by Subdararajan et al. 34 . Integrated,Integrated Gradients is a gradient-based attribution method proposed by Subdararajan et al.34. Integrated,-0.2,0,1,0,1,9,9,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,6,6,0
Integrated Gradients is a gradient-based attribution method proposed by Subdararajan et al. 34 . Integrated,Integrated Gradients is a gradient-based attribution method proposed by Subdararajan et al.34. Integrated,"Gradients is designed to satisfy two fundamental axioms, i.e., sensitivity and implementation invariance,","Gradients is designed to satisfy two fundamental axioms, i.e., sensitivity and implementation invariance,",-0.2,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,1
"Gradients is designed to satisfy two fundamental axioms, i.e., sensitivity and implementation invariance,","Gradients is designed to satisfy two fundamental axioms, i.e., sensitivity and implementation invariance,",and thus generate more reasonable explanations of neural network models than previous approaches such as,and thus generate more reasonable explanations of neural network models than previous approaches such as,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
and thus generate more reasonable explanations of neural network models than previous approaches such as,and thus generate more reasonable explanations of neural network models than previous approaches such as,"Gradient * Input 48, Layer-wise Relevance propagation LRP 49, and DeepLIFT 50 .","Gradient * Input48, Layer-wise Relevance propagation (LRP)49, and DeepLIFT50.",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,1
"Gradient * Input 48, Layer-wise Relevance propagation LRP 49, and DeepLIFT 50 .","Gradient * Input48, Layer-wise Relevance propagation (LRP)49, and DeepLIFT50.",A prerequisite for a reasonable attribution using Integrated Gradients is to identify a baseline input. Take,A prerequisite for a reasonable attribution using Integrated Gradients is to identify a baseline input. Take,-0.2,12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,6,6,0
A prerequisite for a reasonable attribution using Integrated Gradients is to identify a baseline input. Take,A prerequisite for a reasonable attribution using Integrated Gradients is to identify a baseline input. Take,"image networks as an example, the baseline inputs can be pixels equal to zero, constituting a black image. In our","image networks as an example, the baseline inputs can be pixels equal to zero, constituting a black image. In our",-0.2,-12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"image networks as an example, the baseline inputs can be pixels equal to zero, constituting a black image. In our","image networks as an example, the baseline inputs can be pixels equal to zero, constituting a black image. In our","case, however, baseline cannot be simply set to zeros, since genes are seldomly expressed as zeros and picking","case, however, baseline cannot be simply set to zeros, since genes are seldomly expressed as zeros and picking",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"case, however, baseline cannot be simply set to zeros, since genes are seldomly expressed as zeros and picking","case, however, baseline cannot be simply set to zeros, since genes are seldomly expressed as zeros and picking",zeros as baseline will render the explanation biased to certain genes with relatively high expression values. Our,zeros as baseline will render the explanation biased to certain genes with relatively high expression values. Our,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
zeros as baseline will render the explanation biased to certain genes with relatively high expression values. Our,zeros as baseline will render the explanation biased to certain genes with relatively high expression values. Our,"intention is to compute the average normal expression level as background for each gene, and study the effect","intention is to compute the average normal expression level as background for each gene, and study the effect",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"intention is to compute the average normal expression level as background for each gene, and study the effect","intention is to compute the average normal expression level as background for each gene, and study the effect","when a gene is differentially expressed. Hypothesising that genes are normally expressed in most cell lines, we","when a gene is differentially expressed. Hypothesising that genes are normally expressed in most cell lines, we",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"when a gene is differentially expressed. Hypothesising that genes are normally expressed in most cell lines, we","when a gene is differentially expressed. Hypothesising that genes are normally expressed in most cell lines, we","propose to identify suspiciously abnormal values with an interquartile range IQR filter. For each gene, we","propose to identify suspiciously abnormal values with an interquartile range (IQR) filter. For each gene, we",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"propose to identify suspiciously abnormal values with an interquartile range IQR filter. For each gene, we","propose to identify suspiciously abnormal values with an interquartile range (IQR) filter. For each gene, we",calculate IQR of its expression values on all the cell lines. Then expression values that are more than 2.22 times,calculate IQR of its expression values on all the cell lines. Then expression values that are more than 2.22 times,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
calculate IQR of its expression values on all the cell lines. Then expression values that are more than 2.22 times,calculate IQR of its expression values on all the cell lines. Then expression values that are more than 2.22 times,"the IQR away from the median of the data are considered as outliers, which is roughly equivalent to remove the","the IQR away from the median of the data are considered as outliers, which is roughly equivalent to remove the",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"the IQR away from the median of the data are considered as outliers, which is roughly equivalent to remove the","the IQR away from the median of the data are considered as outliers, which is roughly equivalent to remove the",data points that have a z-score larger than 3 in the normal distribution. Thereafter we remove the outliers and,data points that have a z-score larger than 3 in the normal distribution. Thereafter we remove the outliers and,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
data points that have a z-score larger than 3 in the normal distribution. Thereafter we remove the outliers and,data points that have a z-score larger than 3 in the normal distribution. Thereafter we remove the outliers and,compute the average of preserved expression values as the baseline of each gene.,compute the average of preserved expression values as the baseline of each gene.,-0.2,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
compute the average of preserved expression values as the baseline of each gene.,compute the average of preserved expression values as the baseline of each gene.,"After deciding the baseline input, Integrated Gradients computes the integral of the gradients along the path","After deciding the baseline input, Integrated Gradients computes the integral of the gradients along the path",-0.2,12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,6,6,0
"After deciding the baseline input, Integrated Gradients computes the integral of the gradients along the path","After deciding the baseline input, Integrated Gradients computes the integral of the gradients along the path","from the baseline input to the actual input. If we denote the actual input as x and the baseline input as x', the","from the baseline input to the actual input. If we denote the actual input as x and the baseline input as x', the",-0.2,-12,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"from the baseline input to the actual input. If we denote the actual input as x and the baseline input as x', the","from the baseline input to the actual input. If we denote the actual input as x and the baseline input as x', the",integrated gradients can be defined by,integrated gradients can be defined by,-0.2,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
integrated gradients can be defined by,integrated gradients can be defined by,Attribution i  x  =  x i - x ' i   ×,Attributioni (x) = (xi -x',1.42,67.47,0,0,0,9,8.97,-0.03,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,6,6,0
Attribution i  x  =  x i - x ' i   ×,Attributioni (x) = (xi -x',? a 1=0,a=0,0.24,130.94,0,0,0,8.97,5.98,-2.99,0,0,0,1,1,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,1
? a 1=0,a=0,?F  x ' + a ×  x - x ',?F(x' + a × (x -x')),-2.17,17.28,0,0,0,5.98,8.97,2.99,0,0,0,1,1,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,1
?F  x ' + a ×  x - x ',?F(x' + a × (x -x')),?x i,?xi,0.28,36.93,0,0,0,8.97,8.97,0,1,0,0,1,1,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,1
?x i,?xi,"where i refers to the interested dimension of inputs, and a is the interpolated value from x' to x .","where i refers to the interested dimension of inputs, and a is the interpolated value from x' to x.",1,-252.62,0,0,0,8.97,9,0.03,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,6,6,0
"where i refers to the interested dimension of inputs, and a is the interpolated value from x' to x .","where i refers to the interested dimension of inputs, and a is the interpolated value from x' to x.",GNNExplainer,GNNExplainer,2.57,0,1,0,0,9,9,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,1,0,0,0,1,6,6,0
GNNExplainer,GNNExplainer,"Gradient-based methods e.g., Integrated Gradients is suitable to explain models built on grid-like data in the","Gradient-based methods (e.g., Integrated Gradients) is suitable to explain models built on grid-like data in the",-0.2,0,1,0,0,9,9,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,6,6,0
"Gradient-based methods e.g., Integrated Gradients is suitable to explain models built on grid-like data in the","Gradient-based methods (e.g., Integrated Gradients) is suitable to explain models built on grid-like data in the","text or image domain. However, GNN models built in the graph domain are developed to capture the structural","text or image domain. However, GNN models built in the graph domain are developed to capture the structural",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"text or image domain. However, GNN models built in the graph domain are developed to capture the structural","text or image domain. However, GNN models built in the graph domain are developed to capture the structural","information of graphs, and interpreting such models requires to explore how messages are passed through the","information of graphs, and interpreting such models requires to explore how messages are passed through the",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"information of graphs, and interpreting such models requires to explore how messages are passed through the","information of graphs, and interpreting such models requires to explore how messages are passed through the",graph structures 51 . GNNExplainer is one of the explanation methods aiming at analyzing models built in the,graph structures51. GNNExplainer is one of the explanation methods aiming at analyzing models built in the,-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
graph structures 51 . GNNExplainer is one of the explanation methods aiming at analyzing models built in the,graph structures51. GNNExplainer is one of the explanation methods aiming at analyzing models built in the,"graph domain. Comparing with gradient-based methods, GNNExplainer has been testified to be capable of","graph domain. Comparing with gradient-based methods, GNNExplainer has been testified to be capable of",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"graph domain. Comparing with gradient-based methods, GNNExplainer has been testified to be capable of","graph domain. Comparing with gradient-based methods, GNNExplainer has been testified to be capable of","capturing reasonable substructures of graphs such as functional groups of molecules, in the task of molecular","capturing reasonable substructures of graphs such as functional groups of molecules, in the task of molecular",-0.2,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,6,6,1
"capturing reasonable substructures of graphs such as functional groups of molecules, in the task of molecular","capturing reasonable substructures of graphs such as functional groups of molecules, in the task of molecular",Scientific Reports 2025 15:179 https://doi.org/10.1038/s41598-024-83090-3 6,| https://doi.org/10.1038/s41598-024-83090-3,2,69.94,0,0,1,9,8,-1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,6,6,0
"property prediction 33 . Therefore, in this work, we adopt GNNExplainer to interpret the graph convolutional","property prediction33. Therefore, in this work, we adopt GNNExplainer to interpret the graph convolutional",layers and identify the active functional groups of molecular graphs.,layers and identify the active functional groups of molecular graphs.,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
layers and identify the active functional groups of molecular graphs.,layers and identify the active functional groups of molecular graphs.,The theory of GNNExplainer is to identify the most salient subgraph and subset of node features for the,The theory of GNNExplainer is to identify the most salient subgraph and subset of node features for the,-0.12,12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,7,7,0
The theory of GNNExplainer is to identify the most salient subgraph and subset of node features for the,The theory of GNNExplainer is to identify the most salient subgraph and subset of node features for the,models prediction. It can be formulated in an optimization problem:,models prediction. It can be formulated in an optimization problem:,-0.12,-12,0,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
models prediction. It can be formulated in an optimization problem:,models prediction. It can be formulated in an optimization problem:,max,max,0.21,76.11,0,1,0,9,8.97,-0.03,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,7,7,0
max,max,"MI  Y,  G S , X S  = H  Y  - H  Y |G = G S , X = X S  7","MI(Y, (GS, XS)) = H(Y ) -H(Y |G = GS, X = XS)",-0.5,20.34,0,0,1,8.97,8.97,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,7,7,1
"MI  Y,  G S , X S  = H  Y  - H  Y |G = G S , X = X S  7","MI(Y, (GS, XS)) = H(Y ) -H(Y |G = GS, X = XS)",where the mutual information MI reflects the change of models output when using a subgraph G S and subset of,where the mutual information MI reflects the change of models output when using a subgraph GS and subset of,0.86,-96.45,0,1,0,8.97,9,0.03,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,7,7,0
where the mutual information MI reflects the change of models output when using a subgraph G S and subset of,where the mutual information MI reflects the change of models output when using a subgraph GS and subset of,"node features X S . The prediction of the model can be given by Y = F G, X , where F represents the function","node features XS. The prediction of the model can be given by Y = F(G, X), where F represents the function",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"node features X S . The prediction of the model can be given by Y = F G, X , where F represents the function","node features XS. The prediction of the model can be given by Y = F(G, X), where F represents the function","of the model, and G and X denote the input graph and node feature matrix. Although it is infeasible to retrieve","of the model, and G and X denote the input graph and node feature matrix. Although it is infeasible to retrieve",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"of the model, and G and X denote the input graph and node feature matrix. Although it is infeasible to retrieve","of the model, and G and X denote the input graph and node feature matrix. Although it is infeasible to retrieve","the optimal subgraphs and feature subsets to solve the above problem directly, GNNExplainer has proposed","the optimal subgraphs and feature subsets to solve the above problem directly, GNNExplainer has proposed",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"the optimal subgraphs and feature subsets to solve the above problem directly, GNNExplainer has proposed","the optimal subgraphs and feature subsets to solve the above problem directly, GNNExplainer has proposed",their optimization framework to identify high-quality explanations in an empirical way.,their optimization framework to identify high-quality explanations in an empirical way.,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
their optimization framework to identify high-quality explanations in an empirical way.,their optimization framework to identify high-quality explanations in an empirical way.,Drug response prediction,Drug response prediction,1.52,0,1,1,0,9,11,2,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,7,7,0
Drug response prediction,Drug response prediction,"In this section, we present the results of drug sensitivity prediction and the saliency maps of inputs. We experiment","In this section, we present the results of drug sensitivity prediction and the saliency maps of inputs. We experiment",-0.08,0,1,0,0,11,9,-2,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,7,7,0
"In this section, we present the results of drug sensitivity prediction and the saliency maps of inputs. We experiment","In this section, we present the results of drug sensitivity prediction and the saliency maps of inputs. We experiment","with various GNN models with and without involving edge features, and compare their performance with four","with various GNN models with and without involving edge features, and compare their performance with four",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"with various GNN models with and without involving edge features, and compare their performance with four","with various GNN models with and without involving edge features, and compare their performance with four","baseline models, i.e., tCNN 11, GraphDRP 25, DeepCDR 26 and TGSA 27 . Particularly, gene expression data are used","baseline models, i.e., tCNN11, GraphDRP25, DeepCDR26 and TGSA27. Particularly, gene expression data are used",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"baseline models, i.e., tCNN 11, GraphDRP 25, DeepCDR 26 and TGSA 27 . Particularly, gene expression data are used","baseline models, i.e., tCNN11, GraphDRP25, DeepCDR26 and TGSA27. Particularly, gene expression data are used",as cell line features in place of CNV data used in the original research of tCNN and GraphDRP. DeepCDR and,as cell line features in place of CNV data used in the original research of tCNN and GraphDRP. DeepCDR and,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
as cell line features in place of CNV data used in the original research of tCNN and GraphDRP. DeepCDR and,as cell line features in place of CNV data used in the original research of tCNN and GraphDRP. DeepCDR and,"TGSA focused on incorporating multi-omics profiles, whereas our work intends to investigate better profiling","TGSA focused on incorporating multi-omics profiles, whereas our work intends to investigate better profiling",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,7,7,1
"TGSA focused on incorporating multi-omics profiles, whereas our work intends to investigate better profiling","TGSA focused on incorporating multi-omics profiles, whereas our work intends to investigate better profiling","of drug features. For a fair comparison, we used the gene expression only version of DeepCDR and TGSA to","of drug features. For a fair comparison, we used the gene expression only version of DeepCDR and TGSA to",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"of drug features. For a fair comparison, we used the gene expression only version of DeepCDR and TGSA to","of drug features. For a fair comparison, we used the gene expression only version of DeepCDR and TGSA to","explore if our proposed method properly represents the drugs and leads to better prediction. In addition, we","explore if our proposed method properly represents the drugs and leads to better prediction. In addition, we",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"explore if our proposed method properly represents the drugs and leads to better prediction. In addition, we","explore if our proposed method properly represents the drugs and leads to better prediction. In addition, we",decode the developed models to explore the salient functional groups of drug molecules and biomarkers that are,decode the developed models to explore the salient functional groups of drug molecules and biomarkers that are,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
decode the developed models to explore the salient functional groups of drug molecules and biomarkers that are,decode the developed models to explore the salient functional groups of drug molecules and biomarkers that are,potentially responsible for the biochemical activities.,potentially responsible for the biochemical activities.,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
potentially responsible for the biochemical activities.,potentially responsible for the biochemical activities.,Our models were implemented with PyTorch 52 and PyTorch Geometric 53 libraries. The performance of our,Our models were implemented with PyTorch52 and PyTorch Geometric53 libraries. The performance of our,-0.12,12,0,1,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,7,7,0
Our models were implemented with PyTorch 52 and PyTorch Geometric 53 libraries. The performance of our,Our models were implemented with PyTorch52 and PyTorch Geometric53 libraries. The performance of our,"experiments are evaluated by Root Mean Square Error RMSE, Pearson Correlation Coefficient PCC and","experiments are evaluated by Root Mean Square Error (RMSE), Pearson Correlation Coefficient (PCC) and",-0.12,-12,0,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"experiments are evaluated by Root Mean Square Error RMSE, Pearson Correlation Coefficient PCC and","experiments are evaluated by Root Mean Square Error (RMSE), Pearson Correlation Coefficient (PCC) and",Coefficient of Determination  R 2 . We performed a 3-fold cross-validation on our dataset. The mean and the,Coefficient of Determination (R2). We performed a 3-fold cross-validation on our dataset. The mean and the,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,7,7,1
Coefficient of Determination  R 2 . We performed a 3-fold cross-validation on our dataset. The mean and the,Coefficient of Determination (R2). We performed a 3-fold cross-validation on our dataset. The mean and the,standard deviation of the evaluation metrics obtained on the validation set are reported in the following sections.,standard deviation of the evaluation metrics obtained on the validation set are reported in the following sections.,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
standard deviation of the evaluation metrics obtained on the validation set are reported in the following sections.,standard deviation of the evaluation metrics obtained on the validation set are reported in the following sections.,Rediscovery of known drug and cell line responses,Rediscovery of known drug and cell line responses,0.39,0,1,0,1,9,10,1,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,1,7,7,0
Rediscovery of known drug and cell line responses,Rediscovery of known drug and cell line responses,"To test XGDP with the task of rediscovering response levels of known drugs and cell lines, we randomly shuffle","To test XGDP with the task of rediscovering response levels of known drugs and cell lines, we randomly shuffle",-0.07,0,1,1,0,10,9,-1,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,7,7,0
"To test XGDP with the task of rediscovering response levels of known drugs and cell lines, we randomly shuffle","To test XGDP with the task of rediscovering response levels of known drugs and cell lines, we randomly shuffle",all the pairs of drug and cell line and divide the dataset as described above. This strategy ensures one combination,all the pairs of drug and cell line and divide the dataset as described above. This strategy ensures one combination,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
all the pairs of drug and cell line and divide the dataset as described above. This strategy ensures one combination,all the pairs of drug and cell line and divide the dataset as described above. This strategy ensures one combination,"of drug and cell line can present only once in training, validation or testing set, but each drug or cell line can","of drug and cell line can present only once in training, validation or testing set, but each drug or cell line can",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"of drug and cell line can present only once in training, validation or testing set, but each drug or cell line can","of drug and cell line can present only once in training, validation or testing set, but each drug or cell line can",emerge simultaneously in all sets. The rediscovery task is designed to evaluate if the model is able to learn the,emerge simultaneously in all sets. The rediscovery task is designed to evaluate if the model is able to learn the,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
emerge simultaneously in all sets. The rediscovery task is designed to evaluate if the model is able to learn the,emerge simultaneously in all sets. The rediscovery task is designed to evaluate if the model is able to learn the,"reaction pattern of a drug from its response data with several cell lines, and predict the response levels between","reaction pattern of a drug from its response data with several cell lines, and predict the response levels between",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"reaction pattern of a drug from its response data with several cell lines, and predict the response levels between","reaction pattern of a drug from its response data with several cell lines, and predict the response levels between",the drug and other unknown cell lines.,the drug and other unknown cell lines.,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
the drug and other unknown cell lines.,the drug and other unknown cell lines.,Table 1 presents the performances of the proposed method with different GNN layer and compares them,Table 1 presents the performances of the proposed method with different GNN layer and compares them,-0.12,12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,7,7,0
Table 1 presents the performances of the proposed method with different GNN layer and compares them,Table 1 presents the performances of the proposed method with different GNN layer and compares them,"with the baseline models. In the table, GATE and GATv2E refer to GAT and GATv2 convolution with","with the baseline models. In the table, GAT_E and GATv2_E refer to GAT and GATv2 convolution with",-0.12,-12,0,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"with the baseline models. In the table, GATE and GATv2E refer to GAT and GATv2 convolution with","with the baseline models. In the table, GAT_E and GATv2_E refer to GAT and GATv2 convolution with",incorporation of bond types as edge features. It is shown that XGDP with GAT achieves the highest PCC and,incorporation of bond types as edge features. It is shown that XGDP with GAT achieves the highest PCC and,-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
incorporation of bond types as edge features. It is shown that XGDP with GAT achieves the highest PCC and,incorporation of bond types as edge features. It is shown that XGDP with GAT achieves the highest PCC and,"R 2 values, and all XGDP variants and the tCNN model achieve the lowest RMSE. DeepCDR and TGSA with","R2 values, and all XGDP variants and the tCNN model achieve the lowest RMSE. DeepCDR and TGSA with",-0.18,0,1,0,0,9,8.97,-0.03,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,1,7,7,1
"R 2 values, and all XGDP variants and the tCNN model achieve the lowest RMSE. DeepCDR and TGSA with","R2 values, and all XGDP variants and the tCNN model achieve the lowest RMSE. DeepCDR and TGSA with","only expression data obtain the worst RMSE, which is sensible since their research focus lie on incorporation","only expression data obtain the worst RMSE, which is sensible since their research focus lie on incorporation",-0.08,0,1,0,0,8.97,9,0.03,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"only expression data obtain the worst RMSE, which is sensible since their research focus lie on incorporation","only expression data obtain the worst RMSE, which is sensible since their research focus lie on incorporation","of multi-omics profiles for drug response prediction. Compared with GraphDRP, our method extends the node","of multi-omics profiles for drug response prediction. Compared with GraphDRP, our method extends the node",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"of multi-omics profiles for drug response prediction. Compared with GraphDRP, our method extends the node","of multi-omics profiles for drug response prediction. Compared with GraphDRP, our method extends the node","features with the circular atomic descriptor as illustrated in Algorithm 1, and introduces multi-head attention to","features with the circular atomic descriptor as illustrated in Algorithm 1, and introduces multi-head attention to",-0.12,0,1,0,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"features with the circular atomic descriptor as illustrated in Algorithm 1, and introduces multi-head attention to","features with the circular atomic descriptor as illustrated in Algorithm 1, and introduces multi-head attention to",integrate the hidden features of drug and cell line rather than simple concatenation. It is evident in Table 1 that,integrate the hidden features of drug and cell line rather than simple concatenation. It is evident in Table 1 that,-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
integrate the hidden features of drug and cell line rather than simple concatenation. It is evident in Table 1 that,integrate the hidden features of drug and cell line rather than simple concatenation. It is evident in Table 1 that,"our refinement in the architecture leads to a better performance, especially on models with GAT convolution.","our refinement in the architecture leads to a better performance, especially on models with GAT convolution.",-0.12,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"our refinement in the architecture leads to a better performance, especially on models with GAT convolution.","our refinement in the architecture leads to a better performance, especially on models with GAT convolution.","Compared with tCNN, GAT- and GATE-based XGDP outperform tCNN on both PCC and R 2 . Moreover,","Compared with tCNN, GAT- and GAT_E-based XGDP outperform tCNN on both PCC and R2. Moreover,",-0.12,0,1,0,1,9,9,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,7,7,1
"Compared with tCNN, GAT- and GATE-based XGDP outperform tCNN on both PCC and R 2 . Moreover,","Compared with tCNN, GAT- and GAT_E-based XGDP outperform tCNN on both PCC and R2. Moreover,",Method Conv type RMSE  ?  PCC  ?  R 2  ?,Conv type,1.14,62.25,0,1,0,9,7,-2,0,0,1,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,1,7,7,0
Method Conv type RMSE  ?  PCC  ?  R 2  ?,Conv type,GCN 0.027 ± 0.000 0.917 ± 0.001 0.840 ± 0.003,0.027 ± 0.000,0.78,41.87,0,0,1,7,7,0,0,1,0,0,0,0,0,0,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
GCN 0.027 ± 0.000 0.917 ± 0.001 0.840 ± 0.003,0.027 ± 0.000,GraphDRP 25,GraphDRP25,-0.19,-100.98,0,1,0,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
GraphDRP 25,GraphDRP25,GAT 0.042 ± 0.002 0.828 ± 0.011 0.609 ± 0.034,0.042 ± 0.002,-0.18,100.98,0,0,1,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
GAT 0.042 ± 0.002 0.828 ± 0.011 0.609 ± 0.034,0.042 ± 0.002,GCN 0.026 ± 0.000 0.918 ± 0.001 0.843 ± 0.002,0.026 ± 0.000,-1.8,0,1,1,1,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
GCN 0.026 ± 0.000 0.918 ± 0.001 0.843 ± 0.002,0.026 ± 0.000,GAT 0.026 ± 0.000 0.923 ± 0.000 0.851 ± 0.001,0.026 ± 0.000,2.72,0,1,1,1,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
GAT 0.026 ± 0.000 0.923 ± 0.000 0.851 ± 0.001,0.026 ± 0.000,GATE 0.026 ± 0.000 0.922 ± 0.001 0.849 ± 0.001,0.026 ± 0.000,0.14,0,1,1,1,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
GATE 0.026 ± 0.000 0.922 ± 0.001 0.849 ± 0.001,0.026 ± 0.000,XGDP,XGDP,0.45,-100.98,0,1,0,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
XGDP,XGDP,GATv2E 0.026 ± 0.000 0.921 ± 0.001 0.846 ± 0.001,0.846 ± 0.001,-5.35,193.18,0,0,0,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
GATv2E 0.026 ± 0.000 0.921 ± 0.001 0.846 ± 0.001,0.846 ± 0.001,RGCN 0.026 ± 0.000 0.920 ± 0.001 0.845 ± 0.001,0.920 ± 0.001,-0.51,-47.07,0,0,1,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
RGCN 0.026 ± 0.000 0.920 ± 0.001 0.845 ± 0.001,0.920 ± 0.001,RGAT 0.026 ± 0.000 0.920 ± 0.001 0.846 ± 0.002,0.026 ± 0.000,4.02,-45.13,0,1,1,7,7,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,1,7,7,1
RGAT 0.026 ± 0.000 0.920 ± 0.001 0.846 ± 0.002,0.026 ± 0.000,Table 1 . Performance of proposed and baseline models in the task of rediscovering known drug and cell line,Table 1.  Performance of proposed and baseline models in the task of rediscovering known drug and cell line,2.45,-104.12,0,1,0,7,9,2,0,0,1,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,1,7,7,0
Table 1 . Performance of proposed and baseline models in the task of rediscovering known drug and cell line,Table 1.  Performance of proposed and baseline models in the task of rediscovering known drug and cell line,"responses. All the models, except GraghDRP-GAT, achieve similar RMSE ~0.26. Best PCC and R 2 marked","responses. All the models, except GraghDRP-GAT, achieve similar RMSE (~0.26). Best PCC and R2 (marked",-0.06,0,1,0,1,9,9,0,0,1,0,0,0,0,0,0,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
"responses. All the models, except GraghDRP-GAT, achieve similar RMSE ~0.26. Best PCC and R 2 marked","responses. All the models, except GraghDRP-GAT, achieve similar RMSE (~0.26). Best PCC and R2 (marked",in bold is achieved by XGDP-GAT.,in bold) is achieved by XGDP-GAT.,-0.06,0,1,1,0,9,9,0,1,0,0,0,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,7,7,1
in bold is achieved by XGDP-GAT.,in bold) is achieved by XGDP-GAT.,Scientific Reports 2025 15:179 https://doi.org/10.1038/s41598-024-83090-3 7,| https://doi.org/10.1038/s41598-024-83090-3,1.24,69.94,0,0,1,9,8,-1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,0,1,7,7,0
